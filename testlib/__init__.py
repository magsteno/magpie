#### magpielib, tools for converting steno into shavian and shavian into latin

# used to get a list of active dictionaries to pull prefixed terms froms
from plover import config
from typing import Optional, Union, Tuple, List
currentconfig = config.Config(r'.\plover.cfg')

# each chord in the strokes dictionary is assigned a specific consonant cluster or vowel. sorted loosely based on standard shavian order
# rhotic clusters lack the letter ğ‘® because these already exist in the vowel. rhotic vowels lack the R in the chord because these already exist in the final
strokesDict = {
    'initials': {'': '', 'ğ‘¦': 'ğ‘¦',
        'ğ‘': 'ğ‘', 'ğ‘ğ‘£ğ‘®': 'ğ‘ğ‘¤', 'ğ‘ğ‘®': 'ğ‘ğ‘®', 'ğ‘ğ‘¢': 'ğ‘š', 'ğ‘ğ‘¢ğ‘£ğ‘®': 'ğ‘šğ‘¤', 'ğ‘ğ‘¢ğ‘®': 'ğ‘šğ‘®',
        'ğ‘‘': 'ğ‘‘', 'ğ‘‘ğ‘¢': 'ğ‘‘ğ‘¢', 'ğ‘‘ğ‘®': 'ğ‘‘ğ‘®', 'ğ‘‘ğ‘’': 'ğ‘›', 'ğ‘‘ğ‘’ğ‘¢': 'ğ‘›ğ‘¢', 'ğ‘‘ğ‘’ğ‘®': 'ğ‘›ğ‘®',
        'ğ‘’': 'ğ‘’', 'ğ‘’ğ‘¢': 'ğ‘’ğ‘¢', 'ğ‘’ğ‘£ğ‘®': 'ğ‘’ğ‘¤', 'ğ‘’ğ‘®': 'ğ‘’ğ‘®', 'ğ‘•ğ‘‘ğ‘’': 'ğ‘œ', 'ğ‘•ğ‘‘ğ‘’ğ‘¢': 'ğ‘œğ‘¢', 'ğ‘•ğ‘‘ğ‘’ğ‘£ğ‘®': 'ğ‘œğ‘¤', 'ğ‘•ğ‘‘ğ‘’ğ‘®': 'ğ‘œğ‘®',
        'ğ‘‘ğ‘': 'ğ‘“', 'ğ‘‘ğ‘ğ‘£ğ‘®': 'ğ‘“ğ‘¤', 'ğ‘‘ğ‘ğ‘®': 'ğ‘“ğ‘®', 'ğ‘‘ğ‘ğ‘¢': 'ğ‘', 'ğ‘‘ğ‘ğ‘¢ğ‘®': 'ğ‘ğ‘®',
        'ğ‘‘ğ‘£': 'ğ‘”', 'ğ‘‘ğ‘¢ğ‘£': 'ğ‘”ğ‘¢', 'ğ‘‘ğ‘£ğ‘®': 'ğ‘”ğ‘®', 'ğ‘‘ğ‘’ğ‘£': 'ğ‘',
        'ğ‘•': 'ğ‘•', 'ğ‘•ğ‘': 'ğ‘•ğ‘', 'ğ‘•ğ‘ğ‘£ğ‘®': 'ğ‘•ğ‘ğ‘¤', 'ğ‘•ğ‘ğ‘®': 'ğ‘•ğ‘ğ‘®', 'ğ‘•ğ‘‘': 'ğ‘•ğ‘‘', 'ğ‘•ğ‘‘ğ‘®': 'ğ‘•ğ‘‘ğ‘®', 'ğ‘•ğ‘’': 'ğ‘•ğ‘’', 'ğ‘•ğ‘’ğ‘£ğ‘®': 'ğ‘•ğ‘’ğ‘¤', 'ğ‘•ğ‘’ğ‘®': 'ğ‘•ğ‘’ğ‘®', 'ğ‘•ğ‘’ğ‘¢': 'ğ‘•ğ‘’ğ‘¢', 'ğ‘•ğ‘‘ğ‘': 'ğ‘•ğ‘“', 'ğ‘•ğ‘’ğ‘¢ğ‘®': 'ğ‘•ğ‘˜', 'ğ‘•ğ‘¢': 'ğ‘•ğ‘¢', 'ğ‘•ğ‘£ğ‘®': 'ğ‘•ğ‘¤', 'ğ‘•ğ‘ğ‘£': 'ğ‘•ğ‘¥', 'ğ‘•ğ‘‘ğ‘ğ‘£': 'ğ‘•ğ‘¯', 'ğ‘•ğ‘®': 'ğ‘Ÿ',
        'ğ‘’ğ‘': 'ğ‘–', 'ğ‘’ğ‘ğ‘£ğ‘®': 'ğ‘–ğ‘¤', 'ğ‘’ğ‘ğ‘®': 'ğ‘–ğ‘®', 'ğ‘’ğ‘ğ‘¢': 'ğ‘ ',
        'ğ‘‘ğ‘’ğ‘': 'ğ‘—', 'ğ‘‘ğ‘’ğ‘ğ‘¢': 'ğ‘¡',
        'ğ‘’ğ‘¢ğ‘®': 'ğ‘˜', 'ğ‘¢': 'ğ‘¢',
        'ğ‘•ğ‘‘ğ‘’ğ‘ğ‘£': 'ğ‘™', 'ğ‘•ğ‘‘ğ‘’ğ‘ğ‘¢ğ‘£': 'ğ‘™ğ‘¢',
        'ğ‘£': 'ğ‘£', 'ğ‘¢ğ‘£': 'ğ‘£ğ‘¢',
        'ğ‘£ğ‘®': 'ğ‘¤', 'ğ‘®': 'ğ‘®',
        'ğ‘ğ‘£': 'ğ‘¥', 'ğ‘‘ğ‘ğ‘£': 'ğ‘¯'},
    'nonrhotic': {'': '',
        'ğ‘': 'ğ‘', 'ğ‘ğ‘‘': 'ğ‘ğ‘‘', 'ğ‘ğ‘‘ğ‘•': 'ğ‘ğ‘‘ğ‘•', 'ğ‘ğ‘‘ğ‘›': 'ğ‘ğ‘”', 'ğ‘ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘ğ‘”ğ‘•', 'ğ‘ğ‘•': 'ğ‘ğ‘•', 'ğ‘ğ‘•ğ‘›': 'ğ‘ğ‘•ğ‘‘', 'ğ‘ğ‘šğ‘‘': 'ğ‘ğ‘•ğ‘‘',
        'ğ‘š': 'ğ‘š', 'ğ‘šğ‘›': 'ğ‘šğ‘›', 'ğ‘šğ‘›ğ‘Ÿ': 'ğ‘šğ‘›ğ‘Ÿ', 'ğ‘šğ‘Ÿ': 'ğ‘šğ‘Ÿ',
        'ğ‘‘': 'ğ‘‘', 'ğ‘¤ğ‘‘ğ‘›': 'ğ‘‘ğ‘”', 'ğ‘¤ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘‘ğ‘”ğ‘•', 'ğ‘‘ğ‘•': 'ğ‘‘ğ‘•', 'ğ‘‘ğ‘•ğ‘›': 'ğ‘‘ğ‘•ğ‘‘',
        'ğ‘›': 'ğ‘›', 'ğ‘¤ğ‘œ': 'ğ‘›', 'ğ‘¤ğ‘œğ‘‘ğ‘›': 'ğ‘›ğ‘”', 'ğ‘¤ğ‘œğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘›ğ‘”ğ‘•', 'ğ‘›ğ‘Ÿ': 'ğ‘›ğ‘Ÿ', 'ğ‘¤ğ‘œğ‘Ÿ': 'ğ‘›ğ‘Ÿ', 'ğ‘¤ğ‘œğ‘•ğ‘›': 'ğ‘›ğ‘Ÿğ‘›',
        'ğ‘šğ‘œ': 'ğ‘’', 'ğ‘šğ‘œğ‘‘': 'ğ‘’ğ‘‘', 'ğ‘œğ‘‘': 'ğ‘’ğ‘‘', 'ğ‘šğ‘œğ‘‘ğ‘•': 'ğ‘’ğ‘‘ğ‘•', 'ğ‘œğ‘‘ğ‘•': 'ğ‘’ğ‘‘ğ‘•', 'ğ‘šğ‘œğ‘‘ğ‘›': 'ğ‘’ğ‘”', 'ğ‘šğ‘œğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘’ğ‘”ğ‘•', 'ğ‘šğ‘œğ‘•': 'ğ‘’ğ‘•', 'ğ‘œğ‘•': 'ğ‘’ğ‘•', 'ğ‘šğ‘œğ‘•ğ‘›': 'ğ‘’ğ‘•ğ‘‘', 'ğ‘œğ‘•ğ‘›': 'ğ‘’ğ‘•ğ‘‘', 'ğ‘šğ‘œğ‘•ğ‘›ğ‘Ÿ': 'ğ‘’ğ‘•ğ‘‘ğ‘•', 'ğ‘œğ‘•ğ‘›ğ‘Ÿ': 'ğ‘’ğ‘•ğ‘‘ğ‘•', 'ğ‘šğ‘œğ‘‘ğ‘•ğ‘›': 'ğ‘’ğ‘•ğ‘”', 'ğ‘œğ‘‘ğ‘•ğ‘›': 'ğ‘’ğ‘•ğ‘”', 'ğ‘šğ‘œğ‘‘ğ‘•ğ‘›ğ‘Ÿ': 'ğ‘’ğ‘•ğ‘”ğ‘•', 'ğ‘œğ‘‘ğ‘•ğ‘›ğ‘Ÿ': 'ğ‘’ğ‘•ğ‘”ğ‘•',
        'ğ‘œ': 'ğ‘œ', 'ğ‘œğ‘›': 'ğ‘œğ‘›', 'ğ‘œğ‘›ğ‘Ÿ': 'ğ‘œğ‘›ğ‘Ÿ', 'ğ‘œğ‘‘ğ‘›': 'ğ‘œğ‘”', 'ğ‘œğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘œğ‘”ğ‘•', 'ğ‘œğ‘Ÿ': 'ğ‘œğ‘Ÿ',
        'ğ‘“': 'ğ‘“', 'ğ‘“ğ‘‘': 'ğ‘“ğ‘‘', 'ğ‘“ğ‘‘ğ‘•': 'ğ‘“ğ‘‘ğ‘•', 'ğ‘“ğ‘‘ğ‘›': 'ğ‘“ğ‘”', 'ğ‘“ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘“ğ‘”ğ‘•', 'ğ‘“ğ‘•': 'ğ‘“ğ‘•', 'ğ‘“ğ‘•ğ‘›': 'ğ‘“ğ‘•ğ‘‘',
        'ğ‘ğ‘šğ‘¤': 'ğ‘', 'ğ‘ğ‘šğ‘¤ğ‘›': 'ğ‘ğ‘›', 'ğ‘“ğ‘›': 'ğ‘ğ‘›', 'ğ‘ğ‘šğ‘¤ğ‘‘ğ‘›': 'ğ‘ğ‘”', 'ğ‘ğ‘šğ‘¤ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘ğ‘”ğ‘•', 'ğ‘ğ‘šğ‘¤ğ‘Ÿ': 'ğ‘ğ‘Ÿ', 'ğ‘“ğ‘Ÿ': 'ğ‘ğ‘Ÿ',
        'ğ‘‘ğ‘›': 'ğ‘”', 'ğ‘“ğ‘¤ğ‘‘': 'ğ‘”ğ‘‘', 'ğ‘“ğ‘¤ğ‘‘ğ‘•': 'ğ‘”ğ‘‘ğ‘•', 'ğ‘“ğ‘¤ğ‘•': 'ğ‘”ğ‘•', 'ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘”ğ‘•', 'ğ‘“ğ‘¤ğ‘•ğ‘›': 'ğ‘”ğ‘•ğ‘‘',
        'ğ‘“ğ‘¤ğ‘œ': 'ğ‘', 'ğ‘“ğ‘¤ğ‘œğ‘›': 'ğ‘ğ‘›', 'ğ‘“ğ‘¤ğ‘œğ‘Ÿ': 'ğ‘ğ‘Ÿ',
        'ğ‘•': 'ğ‘•', 'ğ‘“ğ‘': 'ğ‘•ğ‘', 'ğ‘“ğ‘ğ‘•': 'ğ‘•ğ‘ğ‘•', 'ğ‘“ğ‘ğ‘•ğ‘›': 'ğ‘•ğ‘ğ‘•ğ‘‘', 'ğ‘“ğ‘ğ‘‘': 'ğ‘•ğ‘ğ‘‘', 'ğ‘“ğ‘ğ‘‘ğ‘•': 'ğ‘•ğ‘ğ‘‘ğ‘•', 'ğ‘•ğ‘›': 'ğ‘•ğ‘‘', 'ğ‘šğ‘‘': 'ğ‘•ğ‘‘', 'ğ‘•ğ‘›ğ‘Ÿ': 'ğ‘•ğ‘‘ğ‘•', 'ğ‘šğ‘‘ğ‘•': 'ğ‘•ğ‘‘ğ‘•', 'ğ‘“ğ‘šğ‘œ': 'ğ‘•ğ‘’', 'ğ‘“ğ‘šğ‘œğ‘‘': 'ğ‘•ğ‘’ğ‘‘', 'ğ‘“ğ‘šğ‘œğ‘‘ğ‘•': 'ğ‘•ğ‘’ğ‘‘ğ‘•', 'ğ‘“ğ‘šğ‘œğ‘•': 'ğ‘•ğ‘’ğ‘•', 'ğ‘“ğ‘šğ‘œğ‘•ğ‘›': 'ğ‘•ğ‘’ğ‘•ğ‘‘', 'ğ‘šğ‘‘ğ‘›': 'ğ‘•ğ‘”', 'ğ‘šğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘•ğ‘”ğ‘•',
        'ğ‘Ÿ': 'ğ‘Ÿ', 'ğ‘šğ‘•': 'ğ‘Ÿ', 'ğ‘šğ‘¤ğ‘œ': 'ğ‘Ÿğ‘›', 'ğ‘šğ‘‘ğ‘•ğ‘›': 'ğ‘Ÿğ‘”', 'ğ‘šğ‘‘ğ‘•ğ‘›ğ‘Ÿ': 'ğ‘Ÿğ‘”ğ‘•',
        'ğ‘ğ‘œ': 'ğ‘–', 'ğ‘ğ‘œğ‘‘': 'ğ‘–ğ‘‘', 'ğ‘ğ‘œğ‘‘ğ‘•': 'ğ‘–ğ‘‘ğ‘•', 'ğ‘ğ‘œğ‘‘ğ‘›': 'ğ‘–ğ‘”', 'ğ‘ğ‘œğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘–ğ‘”ğ‘•',
        'ğ‘ğ‘œğ‘•': 'ğ‘ ', 'ğ‘ğ‘šğ‘•ğ‘›': 'ğ‘ ğ‘›', 'ğ‘ğ‘œğ‘›': 'ğ‘ ğ‘›', 'ğ‘ğ‘šğ‘œğ‘›': 'ğ‘ ğ‘›', 'ğ‘ğ‘šğ‘œğ‘›ğ‘Ÿ': 'ğ‘ ğ‘›ğ‘Ÿ', 'ğ‘ğ‘œğ‘›ğ‘Ÿ': 'ğ‘ ğ‘›ğ‘Ÿ',
        'ğ‘ğ‘¤ğ‘œ': 'ğ‘—', 'ğ‘ğ‘¤ğ‘œğ‘‘': 'ğ‘—ğ‘‘', 'ğ‘ğ‘¤ğ‘œğ‘‘ğ‘•': 'ğ‘—ğ‘‘ğ‘•', 'ğ‘ğ‘¤ğ‘œğ‘‘ğ‘›': 'ğ‘—ğ‘”', 'ğ‘ğ‘¤ğ‘œğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘—ğ‘”ğ‘•',
        'ğ‘ğ‘šğ‘¤ğ‘œ': 'ğ‘¡', 'ğ‘ğ‘¤ğ‘œğ‘•': 'ğ‘¡', 'ğ‘ğ‘šğ‘¤ğ‘œğ‘›': 'ğ‘¡ğ‘›', 'ğ‘ğ‘¤ğ‘œğ‘›': 'ğ‘¡ğ‘›', 'ğ‘ğ‘šğ‘¤ğ‘œğ‘›ğ‘Ÿ': 'ğ‘¡ğ‘›ğ‘Ÿ', 'ğ‘ğ‘¤ğ‘œğ‘›ğ‘Ÿ': 'ğ‘¡ğ‘›ğ‘Ÿ', 'ğ‘ğ‘šğ‘¤ğ‘œğ‘‘ğ‘›': 'ğ‘¡ğ‘”', 'ğ‘ğ‘šğ‘¤ğ‘œğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘¡ğ‘”ğ‘•',
        'ğ‘ğ‘š': 'ğ‘™', 'ğ‘ğ‘šğ‘›': 'ğ‘™ğ‘›', 'ğ‘ğ‘šğ‘›ğ‘Ÿ': 'ğ‘™ğ‘›ğ‘Ÿ', 'ğ‘ğ‘šğ‘œ': 'ğ‘™ğ‘’', 'ğ‘ğ‘šğ‘œğ‘‘': 'ğ‘™ğ‘’ğ‘‘', 'ğ‘ğ‘šğ‘œğ‘‘ğ‘•': 'ğ‘™ğ‘’ğ‘‘ğ‘•', 'ğ‘ğ‘šğ‘œğ‘‘ğ‘›': 'ğ‘™ğ‘’ğ‘”', 'ğ‘ğ‘šğ‘œğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘™ğ‘’ğ‘”ğ‘•', 'ğ‘ğ‘šğ‘œğ‘•': 'ğ‘™ğ‘’ğ‘•', 'ğ‘ğ‘šğ‘œğ‘•ğ‘›': 'ğ‘™ğ‘’ğ‘•ğ‘‘', 'ğ‘ğ‘šğ‘œğ‘•ğ‘›ğ‘Ÿ': 'ğ‘™ğ‘’ğ‘•ğ‘‘ğ‘•', 'ğ‘“ğ‘œ': 'ğ‘™ğ‘œ', 'ğ‘“ğ‘œğ‘›': 'ğ‘™ğ‘œğ‘›', 'ğ‘“ğ‘œğ‘›ğ‘Ÿ': 'ğ‘™ğ‘œğ‘›ğ‘Ÿ', 'ğ‘“ğ‘œğ‘Ÿ': 'ğ‘™ğ‘œğ‘Ÿ', 'ğ‘ğ‘šğ‘‘ğ‘›': 'ğ‘™ğ‘”', 'ğ‘ğ‘šğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘™ğ‘”ğ‘•', 'ğ‘ğ‘šğ‘•': 'ğ‘™ğ‘•', 'ğ‘ğ‘šğ‘•ğ‘›': 'ğ‘™ğ‘•ğ‘‘', 'ğ‘ğ‘šğ‘•ğ‘›ğ‘Ÿ': 'ğ‘™ğ‘•ğ‘‘ğ‘•', 'ğ‘ğ‘šğ‘Ÿ': 'ğ‘™ğ‘Ÿ',
        'ğ‘¤': 'ğ‘¤', 'ğ‘“ğ‘®ğ‘': 'ğ‘¤ğ‘', 'ğ‘“ğ‘®ğ‘ğ‘‘': 'ğ‘¤ğ‘ğ‘‘', 'ğ‘“ğ‘®ğ‘ğ‘‘ğ‘•': 'ğ‘¤ğ‘ğ‘‘ğ‘•', 'ğ‘“ğ‘®ğ‘ğ‘•': 'ğ‘¤ğ‘ğ‘•', 'ğ‘“ğ‘®ğ‘ğ‘•ğ‘›': 'ğ‘¤ğ‘ğ‘•ğ‘‘', 'ğ‘“ğ‘®ğ‘ğ‘š': 'ğ‘¤ğ‘š', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘›': 'ğ‘¤ğ‘šğ‘›', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘Ÿ': 'ğ‘¤ğ‘šğ‘Ÿ',
        'ğ‘¤ğ‘‘': 'ğ‘¤ğ‘‘', 'ğ‘¤ğ‘‘ğ‘•': 'ğ‘¤ğ‘‘ğ‘•', 'ğ‘¤ğ‘‘ğ‘•ğ‘›': 'ğ‘¤ğ‘‘ğ‘•ğ‘‘', 'ğ‘¤ğ‘›': 'ğ‘¤ğ‘›', 'ğ‘“ğ‘®ğ‘¤ğ‘œ': 'ğ‘¤ğ‘›', 'ğ‘¤ğ‘›ğ‘Ÿ': 'ğ‘¤ğ‘›ğ‘Ÿ', 'ğ‘“ğ‘®ğ‘¤ğ‘œğ‘Ÿ': 'ğ‘¤ğ‘›ğ‘Ÿ',
        'ğ‘“ğ‘®ğ‘šğ‘œ': 'ğ‘¤ğ‘’', 'ğ‘“ğ‘®ğ‘šğ‘œğ‘‘': 'ğ‘¤ğ‘’ğ‘‘', 'ğ‘“ğ‘®ğ‘šğ‘œğ‘‘ğ‘•': 'ğ‘¤ğ‘’ğ‘‘ğ‘•', 'ğ‘“ğ‘®ğ‘šğ‘œğ‘•': 'ğ‘¤ğ‘’ğ‘•', 'ğ‘“ğ‘®ğ‘šğ‘œğ‘•ğ‘›': 'ğ‘¤ğ‘’ğ‘•ğ‘‘', 'ğ‘“ğ‘®ğ‘œ': 'ğ‘¤ğ‘œ', 'ğ‘“ğ‘®ğ‘œğ‘›': 'ğ‘¤ğ‘œğ‘›', 'ğ‘“ğ‘®ğ‘œğ‘Ÿ': 'ğ‘¤ğ‘œğ‘Ÿ',
        'ğ‘“ğ‘®ğ‘ğ‘¤': 'ğ‘¤ğ‘“', 'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘‘': 'ğ‘¤ğ‘“ğ‘‘', 'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘‘ğ‘•': 'ğ‘¤ğ‘“ğ‘‘ğ‘•', 'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘‘ğ‘›': 'ğ‘¤ğ‘“ğ‘”', 'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘¤ğ‘“ğ‘”ğ‘•', 'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘•': 'ğ‘¤ğ‘“ğ‘•', 'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘•ğ‘›': 'ğ‘¤ğ‘“ğ‘•ğ‘‘', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘¤': 'ğ‘¤ğ‘', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘¤ğ‘›': 'ğ‘¤ğ‘ğ‘›', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘¤ğ‘Ÿ': 'ğ‘¤ğ‘ğ‘Ÿ',
        'ğ‘“ğ‘®ğ‘¤': 'ğ‘¤ğ‘”', 'ğ‘“ğ‘®ğ‘¤ğ‘‘': 'ğ‘¤ğ‘”ğ‘‘', 'ğ‘“ğ‘®ğ‘¤ğ‘‘ğ‘•': 'ğ‘¤ğ‘”ğ‘‘ğ‘•', 'ğ‘“ğ‘®ğ‘¤ğ‘•': 'ğ‘¤ğ‘”ğ‘•', 'ğ‘“ğ‘®ğ‘¤ğ‘•ğ‘›': 'ğ‘¤ğ‘”ğ‘•ğ‘‘',
        'ğ‘¤ğ‘•': 'ğ‘¤ğ‘•', 'ğ‘¤ğ‘•ğ‘›': 'ğ‘¤ğ‘•ğ‘‘', 'ğ‘¤ğ‘Ÿ': 'ğ‘¤ğ‘Ÿ', 'ğ‘“ğ‘®ğ‘šğ‘•': 'ğ‘¤ğ‘Ÿ', 'ğ‘“ğ‘®ğ‘šğ‘¤ğ‘œ': 'ğ‘¤ğ‘Ÿğ‘›', 'ğ‘“ğ‘®ğ‘šğ‘•ğ‘›': 'ğ‘¤ğ‘Ÿğ‘›',
        'ğ‘“ğ‘®ğ‘ğ‘œ': 'ğ‘¤ğ‘–', 'ğ‘“ğ‘®ğ‘ğ‘œğ‘‘': 'ğ‘¤ğ‘–ğ‘‘', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘œ': 'ğ‘¤ğ‘ ', 'ğ‘“ğ‘®ğ‘ğ‘œğ‘•': 'ğ‘¤ğ‘ ', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘œğ‘›': 'ğ‘¤ğ‘ ğ‘›',
        'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘œ': 'ğ‘¤ğ‘—', 'ğ‘“ğ‘®ğ‘ğ‘¤ğ‘œğ‘‘': 'ğ‘¤ğ‘—ğ‘‘', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘¤ğ‘œ': 'ğ‘¤ğ‘¡', 'ğ‘“ğ‘®ğ‘ğ‘šğ‘¤ğ‘œğ‘›': 'ğ‘¤ğ‘¡ğ‘›',
        'ğ‘“ğ‘šğ‘¤': 'ğ‘¤ğ‘¥', 'ğ‘“ğ‘šğ‘¤ğ‘›': 'ğ‘¤ğ‘¥ğ‘›', 'ğ‘“ğ‘šğ‘¤ğ‘Ÿ': 'ğ‘¤ğ‘¥ğ‘Ÿ', 'ğ‘“ğ‘¤': 'ğ‘¤ğ‘¯', 'ğ‘“ğ‘¤ğ‘›': 'ğ‘¤ğ‘¯ğ‘›', 'ğ‘“ğ‘¤ğ‘Ÿ': 'ğ‘¤ğ‘¯ğ‘Ÿ',
        'ğ‘“ğ‘š': 'ğ‘¥', 'ğ‘“ğ‘ğ‘š': 'ğ‘¥ğ‘', 'ğ‘“ğ‘ğ‘šğ‘‘': 'ğ‘¥ğ‘ğ‘‘', 'ğ‘“ğ‘ğ‘šğ‘‘ğ‘•': 'ğ‘¥ğ‘ğ‘‘ğ‘•', 'ğ‘“ğ‘ğ‘šğ‘•': 'ğ‘¥ğ‘ğ‘•', 'ğ‘“ğ‘ğ‘šğ‘•ğ‘›': 'ğ‘¥ğ‘ğ‘•ğ‘‘', 'ğ‘“ğ‘ğ‘šğ‘¤': 'ğ‘¥ğ‘“', 'ğ‘“ğ‘ğ‘šğ‘¤ğ‘•': 'ğ‘¥ğ‘“ğ‘•', 'ğ‘“ğ‘ğ‘šğ‘¤ğ‘•ğ‘›': 'ğ‘¥ğ‘“ğ‘•ğ‘‘', 'ğ‘“ğ‘ğ‘šğ‘¤ğ‘‘': 'ğ‘¥ğ‘“ğ‘‘', 'ğ‘“ğ‘ğ‘šğ‘¤ğ‘‘ğ‘•': 'ğ‘¥ğ‘“ğ‘‘ğ‘•', 'ğ‘“ğ‘šğ‘‘': 'ğ‘¥ğ‘‘', 'ğ‘“ğ‘šğ‘‘ğ‘•': 'ğ‘¥ğ‘‘ğ‘•', 'ğ‘“ğ‘šğ‘›': 'ğ‘¥ğ‘›', 'ğ‘“ğ‘šğ‘›ğ‘Ÿ': 'ğ‘¥ğ‘›ğ‘Ÿ', 'ğ‘“ğ‘šğ‘‘ğ‘›': 'ğ‘¥ğ‘”', 'ğ‘“ğ‘šğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘¥ğ‘”ğ‘•', 'ğ‘“ğ‘šğ‘Ÿ': 'ğ‘¥ğ‘Ÿ',
        'ğ‘“ğ‘ğ‘¤': 'ğ‘¯', 'ğ‘“ğ‘ğ‘¤ğ‘‘': 'ğ‘¯ğ‘‘', 'ğ‘“ğ‘ğ‘¤ğ‘‘ğ‘•': 'ğ‘¯ğ‘‘ğ‘•', 'ğ‘“ğ‘ğ‘¤ğ‘›': 'ğ‘¯ğ‘›', 'ğ‘“ğ‘ğ‘¤ğ‘›ğ‘Ÿ': 'ğ‘¯ğ‘›ğ‘Ÿ', 'ğ‘“ğ‘ğ‘¤ğ‘‘ğ‘›': 'ğ‘¯ğ‘”', 'ğ‘“ğ‘ğ‘¤ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘¯ğ‘”ğ‘•', 'ğ‘“ğ‘ğ‘¤ğ‘•': 'ğ‘¯ğ‘•', 'ğ‘šğ‘•ğ‘›': 'ğ‘¯ğ‘•ğ‘‘', 'ğ‘“ğ‘ğ‘¤ğ‘Ÿ': 'ğ‘¯ğ‘Ÿ', 'ğ‘“ğ‘ğ‘œ': 'ğ‘¯ğ‘–', 'ğ‘“ğ‘ğ‘œğ‘‘': 'ğ‘¯ğ‘–ğ‘‘', 'ğ‘“ğ‘ğ‘šğ‘œ': 'ğ‘¯ğ‘ ', 'ğ‘“ğ‘ğ‘šğ‘œğ‘›': 'ğ‘¯ğ‘ ğ‘›', 'ğ‘“ğ‘ğ‘œğ‘›': 'ğ‘¯ğ‘ ğ‘›', 'ğ‘“ğ‘ğ‘¤ğ‘œ': 'ğ‘¯ğ‘—', 'ğ‘“ğ‘ğ‘¤ğ‘œğ‘‘': 'ğ‘¯ğ‘—ğ‘‘', 'ğ‘“ğ‘ğ‘šğ‘¤ğ‘œ': 'ğ‘¯ğ‘¡', 'ğ‘“ğ‘ğ‘šğ‘¤ğ‘œğ‘›': 'ğ‘¯ğ‘¡ğ‘›',
        'ğ‘§ğ‘³': 'ğ‘¦', 'ğ‘¨ğ‘ªğ‘§ğ‘³': 'ğ‘°', 'ğ‘§': 'ğ‘§', 'ğ‘¨ğ‘ªğ‘§': 'ğ‘±', 'ğ‘¨': 'ğ‘¨', 'ğ‘¨ğ‘ªğ‘³': 'ğ‘²', '*': 'ğ‘©', '*ğ‘³': 'ğ‘©', 'ğ‘³': 'ğ‘³', 'ğ‘ª': 'ğ‘ª', 'ğ‘ªğ‘³': 'ğ‘´', 'ğ‘¨ğ‘ª': 'ğ‘«', 'ğ‘¨ğ‘§': 'ğ‘µ', 'ğ‘¨ğ‘³': 'ğ‘¬', 'ğ‘ªğ‘§': 'ğ‘¶', 'ğ‘¨ğ‘§ğ‘³': 'ğ‘­', 'ğ‘ªğ‘§ğ‘³': 'ğ‘·', '*ğ‘§': 'ğ‘§ğ‘©', 'ğ‘¨ğ‘ª*ğ‘§ğ‘³': 'ğ‘¾', '*ğ‘§ğ‘³': 'ğ‘¾', 'ğ‘¨*ğ‘§': 'ğ‘¿', 'ğ‘¨ğ‘ª*': 'ğ‘˜ğ‘©'},
    'rhotic': {'ğ‘®': '',
        'ğ‘®ğ‘': 'ğ‘', 'ğ‘®ğ‘ğ‘‘': 'ğ‘ğ‘‘', 'ğ‘®ğ‘ğ‘‘ğ‘•': 'ğ‘ğ‘‘ğ‘•', 'ğ‘®ğ‘ğ‘•': 'ğ‘ğ‘•', 'ğ‘®ğ‘ğ‘•ğ‘›': 'ğ‘ğ‘•ğ‘‘', 'ğ‘®ğ‘š': 'ğ‘š', 'ğ‘®ğ‘šğ‘›': 'ğ‘šğ‘›', 'ğ‘®ğ‘šğ‘Ÿ': 'ğ‘šğ‘Ÿ',
        'ğ‘®ğ‘‘': 'ğ‘‘', 'ğ‘®ğ‘‘ğ‘•': 'ğ‘‘ğ‘•', 'ğ‘®ğ‘‘ğ‘•ğ‘›': 'ğ‘‘ğ‘•ğ‘‘', 'ğ‘®ğ‘›': 'ğ‘›', 'ğ‘®ğ‘¤ğ‘œ': 'ğ‘›', 'ğ‘®ğ‘›ğ‘Ÿ': 'ğ‘›ğ‘Ÿ', 'ğ‘®ğ‘¤ğ‘œğ‘Ÿ': 'ğ‘›ğ‘Ÿ',
        'ğ‘®ğ‘šğ‘œ': 'ğ‘’', 'ğ‘®ğ‘šğ‘œğ‘‘': 'ğ‘’ğ‘‘', 'ğ‘®ğ‘šğ‘œğ‘‘ğ‘•': 'ğ‘’ğ‘‘ğ‘•', 'ğ‘®ğ‘šğ‘œğ‘•': 'ğ‘’ğ‘•', 'ğ‘®ğ‘šğ‘œğ‘•ğ‘›': 'ğ‘’ğ‘•ğ‘‘', 'ğ‘®ğ‘œ': 'ğ‘œ', 'ğ‘®ğ‘œğ‘›': 'ğ‘œğ‘›', 'ğ‘®ğ‘œğ‘Ÿ': 'ğ‘œğ‘Ÿ',
        'ğ‘“ğ‘®': 'ğ‘“', 'ğ‘“ğ‘®ğ‘‘': 'ğ‘“ğ‘‘', 'ğ‘“ğ‘®ğ‘‘ğ‘•': 'ğ‘“ğ‘‘ğ‘•', 'ğ‘“ğ‘®ğ‘•': 'ğ‘“ğ‘•', 'ğ‘“ğ‘®ğ‘•ğ‘›': 'ğ‘“ğ‘•ğ‘‘', 'ğ‘®ğ‘ğ‘šğ‘¤': 'ğ‘', 'ğ‘®ğ‘ğ‘šğ‘¤ğ‘›': 'ğ‘ğ‘›', 'ğ‘“ğ‘®ğ‘›': 'ğ‘ğ‘›', 'ğ‘®ğ‘ğ‘šğ‘¤ğ‘Ÿ': 'ğ‘ğ‘Ÿ', 'ğ‘“ğ‘®ğ‘Ÿ': 'ğ‘ğ‘Ÿ',
        'ğ‘®ğ‘‘ğ‘›': 'ğ‘”', 'ğ‘“ğ‘®ğ‘¤ğ‘œğ‘‘': 'ğ‘”ğ‘‘', 'ğ‘®ğ‘‘ğ‘›ğ‘Ÿ': 'ğ‘”ğ‘•', 'ğ‘“ğ‘®ğ‘¤ğ‘œğ‘•': 'ğ‘”ğ‘•', 'ğ‘“ğ‘®ğ‘¤ğ‘œ': 'ğ‘', 'ğ‘“ğ‘®ğ‘¤ğ‘œğ‘›': 'ğ‘ğ‘›', 'ğ‘“ğ‘®ğ‘¤ğ‘œğ‘Ÿ': 'ğ‘ğ‘Ÿ',
        'ğ‘®ğ‘•': 'ğ‘•', 'ğ‘®ğ‘•ğ‘›': 'ğ‘•ğ‘‘', 'ğ‘®ğ‘šğ‘‘': 'ğ‘•ğ‘‘', 'ğ‘®ğ‘•ğ‘›ğ‘Ÿ': 'ğ‘•ğ‘‘ğ‘•', 'ğ‘®ğ‘šğ‘‘ğ‘•': 'ğ‘•ğ‘‘ğ‘•', 'ğ‘®ğ‘Ÿ': 'ğ‘Ÿ', 'ğ‘®ğ‘šğ‘•': 'ğ‘Ÿ', 'ğ‘®ğ‘šğ‘¤ğ‘œ': 'ğ‘Ÿğ‘›', 'ğ‘®ğ‘šğ‘•ğ‘›': 'ğ‘Ÿğ‘›',
        'ğ‘®ğ‘ğ‘œ': 'ğ‘–', 'ğ‘®ğ‘šğ‘œğ‘‘': 'ğ‘–ğ‘‘', 'ğ‘®ğ‘ğ‘šğ‘œ': 'ğ‘ ', 'ğ‘®ğ‘ğ‘œğ‘•': 'ğ‘ ', 'ğ‘®ğ‘ğ‘šğ‘œğ‘›': 'ğ‘ ğ‘›', 'ğ‘®ğ‘ğ‘œğ‘›': 'ğ‘ ğ‘›',
        'ğ‘®ğ‘ğ‘¤ğ‘œ': 'ğ‘—', 'ğ‘®ğ‘ğ‘¤ğ‘œğ‘‘': 'ğ‘—ğ‘‘', 'ğ‘®ğ‘ğ‘šğ‘¤ğ‘œ': 'ğ‘¡', 'ğ‘®ğ‘ğ‘šğ‘¤ğ‘œğ‘›': 'ğ‘¡ğ‘›',
        'ğ‘®ğ‘¤': 'ğ‘¤', 'ğ‘®ğ‘¤ğ‘›': 'ğ‘¤ğ‘›', 'ğ‘®ğ‘¤ğ‘›ğ‘Ÿ': 'ğ‘¤ğ‘›ğ‘Ÿ', 'ğ‘®ğ‘¤ğ‘Ÿ': 'ğ‘¤ğ‘Ÿ',
        'ğ‘“ğ‘®ğ‘š': 'ğ‘¥', 'ğ‘“ğ‘®ğ‘šğ‘›': 'ğ‘¥ğ‘›', 'ğ‘“ğ‘®ğ‘šğ‘Ÿ': 'ğ‘¥ğ‘Ÿ', 'ğ‘®ğ‘ğ‘š': 'ğ‘¯', 'ğ‘®ğ‘ğ‘šğ‘‘': 'ğ‘¯ğ‘‘', 'ğ‘®ğ‘ğ‘šğ‘‘ğ‘•': 'ğ‘¯ğ‘‘ğ‘•', 'ğ‘®ğ‘ğ‘šğ‘›': 'ğ‘¯ğ‘›', 'ğ‘®ğ‘ğ‘šğ‘•': 'ğ‘¯ğ‘•', 'ğ‘®ğ‘ğ‘šğ‘Ÿ': 'ğ‘¯ğ‘Ÿ',
        'ğ‘¨': 'ğ‘¸', 'ğ‘ª': 'ğ‘¹', 'ğ‘§': 'ğ‘º', 'ğ‘³': 'ğ‘»', '*': 'ğ‘¼', '*ğ‘³': 'ğ‘¼', 'ğ‘¨ğ‘ªğ‘§ğ‘³': 'ğ‘½', 'ğ‘§ğ‘³': 'ğ‘½', 'ğ‘¨ğ‘ª': 'ğ‘«ğ‘¼', 'ğ‘¨ğ‘ª*': 'ğ‘˜ğ‘«ğ‘¼', '*ğ‘§ğ‘³': 'ğ‘˜ğ‘¼'}
}

# === dictionary functions ===
def comparejsons() -> None:
    import plover

    # reload and compare current plover config to 'briefsDict'
    currentconfig.load()
    enabledjsons = [path for (path, enabled) in currentconfig.__getitem__('dictionaries') if path.endswith('json') and enabled]
    if enabledjsons != currentjsons:
        reloadjsons(enabledjsons)

def reloadjsons(current: List[str] = [path for (path, enabled) in currentconfig.__getitem__('dictionaries') if path.endswith('json') and enabled]) -> None:
    import json, plover
    global currentjsons, briefsDict

    currentjsons = current
    # dictionary for holding briefs
    briefsDict = {}
    # import briefsDict entries from files listed in currentjsons
    for file in currentjsons[::-1]:
        with open(file, encoding='UTF8') as briefsfile:
            filedata = briefsfile.read()
            briefsPacked = json.loads(filedata)

            # extract from the file only keys beginning with a @, add them to briefsDict
            briefsPacked = list(filter(lambda k: k[0][:1] == '@', briefsPacked.items()))
            briefsDict = {**briefsDict, **{k[1:]: v.split(',,,') for k, v in briefsPacked}}
    del filedata, briefsPacked

def reloaddicts() -> None:
    import plover, os
    global latin, standardise

    # refresh list of jsons
    currentconfig.load()

    # dictionary to hold the necessary parts of the readlex (Shavian to orthodox dicitonary) in memory
    latin = {}
    # dictionary for correcting 'steno spellings' to readlex standard
    standardise = {}
    with open('.\\shavian\\tsv.cfg') as tsvcfg:
        list = tsvcfg.readlines()
        for tsvdir in list:
            if not os.path.isabs(tsvdir):
                tsvdir = '.\\shavian\\' + tsvdir.replace('\n', '')
            with open(tsvdir, encoding='UTF8') as file:
                for line in file.readlines():
                    line = line.replace('\n','')
                    #split lines and take word and frequency data
                    split = line.split("\t")
                    orth = split[0]
                    #entries in readlex marked with * are corrections of steno spelling
                    if orth[:1] == '*':
                        sten = split[1]
                        standardise[sten] = [orth[1:], sten]
                    else:
                        shav = split[1]
                        freq = int(split[2])
                        if shav not in latin:
                            latin[shav] = {orth: freq}
                        else:
                            latin[shav][orth] = freq
        for entry in latin:
            latin[entry] = [shav for shav, freq in sorted(latin[entry].items(), key=lambda freq: freq[1], reverse=True)]
    reloadjsons()

# initial load of dictionaries
reloaddicts()



# === utilities ===
### returns a decimal value based on booleans values of items in tuple; big-endian
def binarybools(bools: tuple) -> int:
    val = 0
    for i, num in enumerate(reversed(bools)):
        val += 2**i * bool(num)
    return val

### returns $first, changing a final ğ‘© to an ğ‘« if $last starts with a vowel
def schwu(first: str, last: str) -> str:
    import re
    if first[-1:] == 'ğ‘©' and re.match('[ğ‘¦-ğ‘­,ğ‘°-ğ‘¾]', last[:1]) is not None:
        return first[:-1] + 'ğ‘«'
    else: return first

### returns $s, changing a final ğ‘› or ğ‘Ÿ with devoicing or schwa
def devoice(s: str, a: int) -> str:
    import re

    # a = 0 means no apostrophe,
    # = 1 means with apostrophe,
    # and = 2 means with apostrophe and schwa
    lb = max(0, a-1) * '(?:'
    rb = max(0, a-1) * "'?)"

    if s[-1] not in 'ğ‘‘ğ‘•ğ‘›ğ‘Ÿ' or not s:
        return s
    # voices ğ‘• and ğ‘‘ for the sake of testing
    if ord(s[-1]) < 66650:
        s = s[:-1] + chr(ord(s[-1]) + 10)

    # $vl marks exceptions to devoicing
    vl = {'ğ‘›': 'ğ‘‘', 'ğ‘Ÿ': 'ğ‘•-ğ‘—'}[s[-1]]
    # substitute ğ‘› or ğ‘Ÿ for ğ‘‘ or ğ‘• if previous letter is devoiced
    output = re.sub(f"(.+[ğ‘-ğ‘—ğ‘£](?<![{vl}])'?){s[-1]}", f'\\1{vl[0]}', s)
    # remove apostrophe
    if not a and output[-2] == "'":
        output = output[:-2] + output[-1]
    # insert schwa where necessary
    output = re.sub(f'(.+?)({lb}([ğ‘‘ğ‘›])|[ğ‘•-ğ‘—ğ‘Ÿ-ğ‘¡]){rb}((?(3)ğ‘›|ğ‘Ÿ))$', r'\1\2ğ‘©\4', output)
    return output

### searches for $stroke in strokesDict, returning None if not found
# latinOut = True will return latin spelling if available
def briefsDict_search(stroke: str, latinOut: bool = False, standard: bool = False) -> Optional[str]:
    comparejsons()
    if stroke in briefsDict:
        output = briefsDict[stroke][-latinOut]
    else:
        output = None
    return output

### separates $shav into words and the joiners that surround them and returns them in a list
# '{^}cat{^} -> ['{^', '', '}', 'cat', '{^}']
# '{^cat}' -> ['{^', 'cat', '}', '', None]
# 'cat{^}' -> [None, None, None, 'cat', '{^}']
def parse_joiners(shav: Union[str, Tuple[str, ...]], groups: Tuple[str, ...] = ('0', '1', '2', '3', '4')) -> List[Union[str, None]]:
    import re

    # shav, if tuple or list, will be converted into a string, with None values ignored
    # the primary purpose of this is so the output can be fed back in
    if type(shav) != str:
        shav = ''.join([(i or '') for i in shav])
    dissect = re.match(r'^(?:({\^)([^\{\}]*)(}))?(?:{\^})*(.*?)(?:{\^})*(?<=({\^}))?$', shav).groups()
    sections = []
    # alternative groupings can be specified with $groups
    # parse_joiners('cat', ('012', '34')) == [None, 'cat']
    for combination in groups:
        sections.append(None)
        for part in combination:
            part = dissect[int(part)]
            if part is not None:
                sections[-1] = (sections[-1] or '') + part

    if len(sections) == 1:
        sections = ''.join(sections)
    return sections

fingerspelling = {
    'righthand': ['ğ‘®ğ‘šğ‘œ', 'ğ‘®', 'ğ‘š', 'ğ‘œ', 'ğ‘“ğ‘®', 'ğ‘ğ‘š', 'ğ‘¤ğ‘œ', 'ğ‘“', 'ğ‘', 'ğ‘¤', 'ğ‘“ğ‘ğ‘¤', 'ğ‘“ğ‘®ğ‘ğ‘š', 'ğ‘ğ‘šğ‘¤ğ‘œ'],
    'numbers': [
        [    '0',    '0s',   '0th',  '0ths',      'zero',    'zeroes',    'zeroth',   'zeroths',
             '0',    '0ğ‘Ÿ',    '0ğ‘”',   '0ğ‘”ğ‘•',       'ğ‘Ÿğ‘½ğ‘´',      'ğ‘Ÿğ‘½ğ‘´ğ‘Ÿ',      'ğ‘Ÿğ‘½ğ‘´ğ‘”',     'ğ‘Ÿğ‘½ğ‘´ğ‘”ğ‘•'],
        [    '1',    '1s',   '1st',  '1sts',       'one',      'ones',     'first',    'firsts',
             '1',    '1ğ‘Ÿ',   '1ğ‘•ğ‘‘',  '1ğ‘•ğ‘‘ğ‘•',       'ğ‘¢ğ‘³ğ‘¯',      'ğ‘¢ğ‘³ğ‘¯ğ‘Ÿ',      'ğ‘“ğ‘»ğ‘•ğ‘‘',     'ğ‘“ğ‘»ğ‘•ğ‘‘ğ‘•'],
        [    '2',    '2s',   '2nd',  '2nds',       'two',      'twos',    'second',   'seconds',
             '2',    '2ğ‘Ÿ',    '2ğ‘›',   '2ğ‘›ğ‘Ÿ',        'ğ‘‘ğ‘µ',       'ğ‘‘ğ‘µğ‘Ÿ',    'ğ‘•ğ‘§ğ‘’ğ‘©ğ‘¯ğ‘›',   'ğ‘•ğ‘§ğ‘’ğ‘©ğ‘¯ğ‘›ğ‘Ÿ'],
        [    '3',    '3s',   '3rd',  '3rds',     'three',    'threes',     'third',    'thirds',
             '3',    '3ğ‘Ÿ',    '3ğ‘›',   '3ğ‘›ğ‘Ÿ',       'ğ‘”ğ‘®ğ‘°',      'ğ‘”ğ‘®ğ‘°ğ‘Ÿ',       'ğ‘”ğ‘»ğ‘›',      'ğ‘”ğ‘»ğ‘›ğ‘Ÿ'],
        [    '4',    '4s',   '4th',  '4ths',      'four',     'fours',    'fourth',   'fourths',
             '4',    '4ğ‘Ÿ',    '4ğ‘”',   '4ğ‘”ğ‘•',        'ğ‘“ğ‘¹',       'ğ‘“ğ‘¹ğ‘Ÿ',       'ğ‘“ğ‘¹ğ‘”',      'ğ‘“ğ‘¹ğ‘”ğ‘•'],
        [    '5',    '5s',   '5th',  '5ths',      'five',     'fives',     'fifth',    'fifths',
             '5',    '5ğ‘Ÿ',    '5ğ‘”',   '5ğ‘”ğ‘•',       'ğ‘“ğ‘²ğ‘',      'ğ‘“ğ‘²ğ‘ğ‘Ÿ',      'ğ‘“ğ‘¦ğ‘“ğ‘”',     'ğ‘“ğ‘¦ğ‘“ğ‘”ğ‘•'],
        [    '6',    '6s',   '6th',  '6ths',       'six',     'sixes',     'sixth',    'sixths',
             '6',    '6ğ‘Ÿ',    '6ğ‘”',   '6ğ‘”ğ‘•',      'ğ‘•ğ‘¦ğ‘’ğ‘•',    'ğ‘•ğ‘¦ğ‘’ğ‘•ğ‘©ğ‘Ÿ',     'ğ‘•ğ‘¦ğ‘’ğ‘•ğ‘”',    'ğ‘•ğ‘¦ğ‘’ğ‘•ğ‘”ğ‘•'],
        [    '7',    '7s',   '7th',  '7ths',     'seven',    'sevens',   'seventh',  'sevenths',
             '7',    '7ğ‘Ÿ',    '7ğ‘”',   '7ğ‘”ğ‘•',     'ğ‘•ğ‘§ğ‘ğ‘©ğ‘¯',    'ğ‘•ğ‘§ğ‘ğ‘©ğ‘¯ğ‘Ÿ',    'ğ‘•ğ‘§ğ‘ğ‘©ğ‘¯ğ‘”',   'ğ‘•ğ‘§ğ‘ğ‘©ğ‘¯ğ‘”ğ‘•'],
        [    '8',    '8s',   '8th',  '8ths',     'eight',    'eights',    'eighth',   'eighths',
             '8',    '8ğ‘Ÿ',    '8ğ‘”',   '8ğ‘”ğ‘•',        'ğ‘±ğ‘‘',       'ğ‘±ğ‘‘ğ‘•',       'ğ‘±ğ‘‘ğ‘”',      'ğ‘±ğ‘‘ğ‘”ğ‘•'],
        [    '9',    '9s',   '9th',  '9ths',      'nine',     'nines',     'ninth',    'ninths',
             '9',    '9ğ‘Ÿ',    '9ğ‘”',   '9ğ‘”ğ‘•',       'ğ‘¯ğ‘²ğ‘¯',      'ğ‘¯ğ‘²ğ‘¯ğ‘Ÿ',      'ğ‘¯ğ‘²ğ‘¯ğ‘”',     'ğ‘¯ğ‘²ğ‘¯ğ‘”ğ‘•'],
        [   '10',   '10s',  '10th', '10ths',       'ten',      'tens',     'tenth',    'tenths',
            '10',   '10ğ‘Ÿ',   '10ğ‘”',  '10ğ‘”ğ‘•',       'ğ‘‘ğ‘§ğ‘¯',      'ğ‘‘ğ‘§ğ‘¯ğ‘Ÿ',      'ğ‘‘ğ‘§ğ‘¯ğ‘”',     'ğ‘‘ğ‘§ğ‘¯ğ‘”ğ‘•'],
        [   '11',   '11s',  '11th', '11ths',    'eleven',   'elevens',  'eleventh', 'elevenths',
            '11',   '11ğ‘Ÿ',   '11ğ‘”',  '11ğ‘”ğ‘•',    'ğ‘¦ğ‘¤ğ‘§ğ‘ğ‘©ğ‘¯',   'ğ‘¦ğ‘¤ğ‘§ğ‘ğ‘©ğ‘¯ğ‘Ÿ',   'ğ‘¦ğ‘¤ğ‘§ğ‘ğ‘©ğ‘¯ğ‘”',  'ğ‘¦ğ‘¤ğ‘§ğ‘ğ‘©ğ‘¯ğ‘”ğ‘•'],
        [   '12',   '12s',  '12th', '12ths',    'twelve',   'twelves',   'twelfth',  'twelfths',
            '12',   '12ğ‘Ÿ',   '12ğ‘”',  '12ğ‘”ğ‘•',     'ğ‘‘ğ‘¢ğ‘§ğ‘¤ğ‘',    'ğ‘‘ğ‘¢ğ‘§ğ‘¤ğ‘ğ‘Ÿ',    'ğ‘‘ğ‘¢ğ‘§ğ‘¤ğ‘“ğ‘”',   'ğ‘‘ğ‘¢ğ‘§ğ‘¤ğ‘“ğ‘”ğ‘•']],
    'ğ‘':  'P', 'ğ‘š':  'B', 'ğ‘‘':  'T', 'ğ‘›':  'D', 'ğ‘’':  'K',  'ğ‘œ': 'G',
    'ğ‘“':  'F', 'ğ‘':  'V', 'ğ‘”': 'TH', 'ğ‘': 'DH', 'ğ‘•':  'S', 'ğ‘Ÿ':  'Z',
    'ğ‘–': 'SH', 'ğ‘ ': 'ZH', 'ğ‘—': 'CH', 'ğ‘¡':  'J', 'ğ‘˜':  'Y', 'ğ‘¢':  'W',
    'ğ‘™': 'NG', 'ğ‘£':  'H', 'ğ‘¤':  'L', 'ğ‘®':  'R', 'ğ‘¥':  'M', 'ğ‘¯':  'N',
    'ğ‘§ğ‘³': 'I', 'ğ‘§':  'E', 'ğ‘¨':  'A', '':   'É™', 'ğ‘³':  'U', 'ğ‘ª':  'O',
    'exceptions': {None: None, 'ğ‘’ğ‘£': 'C', 'ğ‘’ğ‘¢': 'Q', 'ğ‘‘ğ‘’ğ‘£ğ‘®': 'X'}
}
### returns a string with a number or ordinal, or with letters for fingerspelling
# ('#-ğ‘œ') -> '3' # ('#ğ‘‘ğ‘ğ‘£-ğ‘ğ‘šğ‘¤ğ‘œğ‘‘') -> 'twelfth'
# ('ğ‘‘ğ‘-ğ‘ğ‘¤') -> 'f' # ('ğ‘•ğ‘‘ğ‘’ğ‘ğ‘£*ğ‘ğ‘¤') -> 'NG' # ('#ğ‘’ğ‘-ğ‘ğ‘¤') -> 'ğ‘–'
def deschiffresetdeslettres(stroke: Tuple[str], latinOut: bool = False) -> Optional[str]:
    import re
    # https://regex101.com/r/e8WjLD/1
    parts = re.match(r'^(#)?([ğ‘•ğ‘‘ğ‘’ğ‘ğ‘¢ğ‘£ğ‘®]+(?=-|\*[^ğ‘®]))?(?:-|([ğ‘¨ğ‘ª*ğ‘§ğ‘³]+(?=(ğ‘®))?))([ğ‘“ğ‘®ğ‘ğ‘šğ‘¤ğ‘œ]+)(ğ‘‘)?(ğ‘•)?$', stroke[0])
    # if no match or too many strokes
    if len(stroke) > 1 or not parts:
        return None
    # $hash takes #, $initial takes initial consonants
    # $vowel takes vowels and *, $r takes 'R' only if vowel is present
    # $final takes final consonants, $t takes 'T', $s takes 'S'
    (hash, initial, vowel, r, final, t, s) = parts.groups()

    # -ğ‘ğ‘¤ marks fingerspelling, using # to mark shavian and * to mark capitalisation
    if final.replace('ğ‘®', '') == 'ğ‘ğ‘¤':
        letter = None
        # if initial is present, we are fingerspelling a consonant
        if initial:
            if initial in strokesDict['initials'] and len(strokesDict['initials'][initial]) == 1:
                # the consonant is valid for shavian fingerspelling (hash marks shavian)
                letter = strokesDict['initials'][initial]
                if not hash:
                    letter = fingerspelling[letter]

            elif initial in fingerspelling['exceptions']:
                # the consonant is an exception with no shavian equivalent
                if not hash:
                    letter = fingerspelling['exceptions'][initial]

            if letter and not vowel:
                # vowel represents the * key
                letter = f'{{>}}{letter.lower()}'

        # if vowel is present, we are fingerspelling a vowel
        elif vowel:
            # if r is present, rhotic (otherwise nonrhotic)
            rhoticity = (not bool(r)) * 'non' + 'rhotic'
            if hash:
                if vowel in strokesDict[rhoticity] and len(strokesDict[rhoticity][vowel]) == 1:
                    # the vowel is valid for shavian fingerspelling
                    letter = strokesDict[rhoticity][vowel]

            elif vowel.replace('*', '') in fingerspelling:
                # when not shavian, vowel must be present in fingerspelling dictionary
                # if rhotic, an r will be placed after the vowel
                letter = fingerspelling[vowel.replace('*', '')] + bool(r) * 'r'
                if not re.fullmatch(r'(.\*|\*.*)', vowel):
                    # vowel should be lowercase if no *
                    letter = f'{{>}}{letter.lower()}'

        # attempt to wrap letter in {&} glue, else if no letter, return None
        return re.sub('({>})?(.+)', r'\1{&\2}', letter or '') or None

    # #- marks a number, optionally with N- (ğ‘‘ğ‘ğ‘£-) marking that it should be spelt out
    # in adition to the numbers, -ğ‘‘ and -ğ‘• can be used for ordinals and plurals
    elif hash and (initial == 'ğ‘‘ğ‘ğ‘£' or not initial) and not vowel:
        if final in fingerspelling['righthand']:
            number = fingerspelling['righthand'].index(final)
            number = fingerspelling['numbers'][number][binarybools((not latinOut, initial, t, s))]
            #marks only single digits with {&} glue
            if not binarybools((initial, t, s)):
                number = f'{{&{number}}}'
            return number

    return None



# === conversion functions for steno dictionaries ===

### 'ğ‘•ğ‘‘ğ‘’ğ‘£ğ‘®ğ‘¨ğ‘ªğ‘§ğ‘šğ‘•' to 'ğ‘œğ‘¤ğ‘±ğ‘Ÿ'
def stroke_to_shav(stroke: str) -> str:
    import re

    # === segmenting strokes for searching and parsing ===
    # to make ğ‘’ğ‘¢ğ‘® pass the regex
    if stroke.replace('#', '') == 'ğ‘’ğ‘¢ğ‘®': stroke += '-'

    # the hash symbol is used to mark where two words join
    if stroke == '#': return '{^}'

    # split 'stroke' into syllable segments (initial, vowels, final) and if prefixed with #, mark for joining to next syllable
    dissect = re.fullmatch(r'(#?)([ğ‘•ğ‘‘ğ‘’ğ‘ğ‘¢ğ‘£ğ‘®]*)([ğ‘¨ğ‘ª*ğ‘§ğ‘³-]+)([ğ‘“ğ‘®ğ‘ğ‘šğ‘¤ğ‘œğ‘‘ğ‘•ğ‘›ğ‘Ÿ]*)', stroke)
    if dissect is None:
        raise KeyError(f'{stroke} is an nvalid stroke')
    (joinsNext, initial, vowel, final) = dissect.groups()


    # === preparation for conversion ===
    # A* = schwa attached to front of syllable
    if vowel.replace('ğ‘³','') == 'ğ‘¨*':
        joinsNext = True
        vowel = vowel.replace('ğ‘¨','')

    # # -TZ - alternative joiner (like #)
    # if final.replace('ğ‘®','') == 'ğ‘‘ğ‘Ÿ':
    #     joinsNext = True
    #     final = final.replace('ğ‘‘ğ‘Ÿ','')

    # determines rhoticity
    if final.replace('ğ‘Ÿ', '') in list(strokesDict['rhotic'].keys()):
        rhoticity = 'rhotic'
    else:
        rhoticity = 'nonrhotic'

    # converts Y- into schwi
    if initial == 'ğ‘’ğ‘¢ğ‘®' and (vowel == '-' or (rhoticity == 'nonrhotic' and vowel + strokesDict[rhoticity][final] == '*ğ‘•ğ‘‘')):
        initial = 'ğ‘¦'
        if final == 'ğ‘®':
            vowel = '*'
        elif rhoticity == 'rhotic':
            raise KeyError(f'{stroke} is an invalid stroke')
        elif vowel == '-':
            vowel = ''

    # rhotic compounds with long vowels
    compound = ''
    if rhoticity == 'rhotic' and vowel not in strokesDict['rhotic']:
        compound = strokesDict['nonrhotic'][vowel]
        vowel = '*'

    # schwaed plurals
    plural = ''
    if 'ğ‘Ÿ' in final and final.replace('ğ‘Ÿ', '') in strokesDict[rhoticity]:
        pluralless = strokesDict[rhoticity][final.replace('ğ‘Ÿ', '')]
        if pluralless and pluralless[-1:] in 'ğ‘•ğ‘Ÿğ‘–ğ‘ ğ‘—ğ‘¡':
            final = final.replace('ğ‘Ÿ', '')
            plural = 'ğ‘©ğ‘Ÿ'


    # === conversion from steno to raw shavian (illegal strokes will raise KeyError) ===
    shav = strokesDict['initials'][initial] + compound + strokesDict[rhoticity][vowel] + strokesDict[rhoticity][final]
    for i, j in {'ğ‘˜ğ‘µ': 'ğ‘¿', 'ğ‘˜ğ‘¿': 'ğ‘¿', 'ğ‘¾ğ‘¼': 'ğ‘°ğ‘¼'}.items():
        shav = shav.replace(i, j)


    # === determination of word boundaries ===
    #if vowel is schwa or schwi, or ğ‘¾/ğ‘½ as a suffix, then {^} at start of syllable
    if (
        any(s in shav for s in 'ğ‘©ğ‘¼ğ‘¾ğ‘½')
        and not (
            any(v in shav for v in 'ğ‘§ğ‘«')
            or (len(vowel) > 3)
            or (vowel == '*' and joinsNext)
        )
    ) and (not compound) or initial == 'ğ‘¦':
        if vowel == '*' and final == '':
            raise KeyError('* cannot end a word (try *U)')
        shav = '{^}' + shav

    # will except words that shouldn't be changed, like ğ‘²ğ‘¼ğ‘¯ (ğ‘Â· ğ‘²ğ‘¼ğ‘¦ğ‘™) ğ‘¯ ğ‘šğ‘¶ğ‘™
    if shav not in latin:
        # ğ‘¯ to ğ‘™ after rhotic compound
        shav = re.sub('(ğ‘½|[ğ‘¬-ğ‘²ğ‘´-ğ‘·ğ‘¿]ğ‘¼)(ğ‘¯)', r'\1ğ‘™', shav)

        # ğ‘¦ before ğ‘™ after long vowel
        shav = re.sub('([ğ‘¬-ğ‘²ğ‘´-ğ‘·ğ‘½ğ‘¿]ğ‘¼?)(ğ‘™)', r'\1ğ‘¦\2', shav)

    if joinsNext:
        shav += '{^}'

    return shav + plural


### ('#ğ‘‘ğ‘*', 'ğ‘‘ğ‘ğ‘£ğ‘§ğ‘‘', 'ğ‘’ğ‘¢ğ‘®-ğ‘šğ‘œğ‘•') into 'ğ‘“ğ‘©ğ‘¯ğ‘§ğ‘‘ğ‘¦ğ‘’ğ‘•'
def steno_to_shav(steno: Tuple[str, ...], standard: bool = False) -> Tuple[Optional[str], int, bool]:
    output = None
    past = False

    # special exception for the ğ‘³ -> ğ‘© brief
    if steno[-1] == 'ğ‘³':
        raise KeyError('article, not part of stroke')

    # == separate variant markers from strokes ==
    for varindex in range(len(steno)):
        if steno[varindex] == '-ğ‘®ğ‘š' and all(chain == '-ğ‘®ğ‘š' for chain in steno[varindex:]):
            variant = len(steno) - varindex
            break
    else:
        variant = 0

    for stroke in steno[:-variant or None]:
        if output == '{^}{^}':
            raise KeyError(f'outline {steno} starts with no phonetic information')

        dz = False

        syllable = briefsDict_search(stroke)
        previous = parse_joiners(output or '{^}', ('0123','4'))

        # == convert stroke to dissected tuple ==
        # 'ğ‘’ğ‘¢ğ‘®-ğ‘šğ‘œğ‘•' to ('{^}', 'ğ‘¦ğ‘’ğ‘•', None)
        if syllable is not None: # if stroke is in strokesDict, split
            syllable = parse_joiners(syllable)
        # if stroke was not in strokesDict, or no joiners in output
        if syllable is None or syllable[0] == syllable[4]:
            stroke = stroke_to_shav(stroke)
            syllable = parse_joiners(stroke, ('012', '3', '4'))
        # else, if joiners in output (stroke is a prefix stroke)
        else:
            syllable = parse_joiners(syllable, ('02', '1', '34'))
            if any(x == syllable[1] for x in ['ğ‘›', 'ğ‘Ÿ', "'ğ‘Ÿ"]):
                dz = True
                if syllable[1] == 'ğ‘›':
                    past = True

        # == update previous and commit to output if strokes connect ==
        previous[0] = schwu(previous[0], syllable[1] or '')
        # if joiner at end of $previous or start of $syllable
        if previous[1] or syllable[0]:
            # adds syllable to output without intermediary joiners; None -> ''
            output = ''.join([(x or '') for x in previous[:bool(output)] + syllable[bool(output):]])
            if dz:
                output = devoice(output, 1)
        else:
            raise KeyError('Word boundary within outline')

    if standard and output is not None:
        output = parse_joiners(output, ('012', '3', '4'))
        if output[1] in standardise:
            output = standardise[output[1]][bool(variant)]
            if variant:
                variant -= 1
        output = ''.join([(x or '') for x in output])

    return output, variant, past

def shav_to_latin(shav: str, variant: int = 0, past: bool = False) -> str:
    import re
    output = parse_joiners(shav, ('012', '3', '4'))
    shav = output[1]
    output[1] = []

    if shav in latin:
        output[1] += latin[shav]

    suffixsplit = re.fullmatch('(.*?[^ğ‘©])(ğ‘©?[ğ‘›ğ‘Ÿ]|[ğ‘‘ğ‘•]|ğ‘¼ğ‘Ÿ?|ğ‘¦ğ‘™ğ‘Ÿ?)$', shav)
    if suffixsplit is not None:
        (shav, suffix) = suffixsplit.groups()
        for k, v in {'ğ‘©?[ğ‘‘ğ‘›]': 'ed', 'ğ‘©': 'e', 'ğ‘¼': 'er', 'ğ‘¦ğ‘™': 'ing', '[ğ‘•ğ‘Ÿ]': 's'}.items():
            suffix = re.sub(k, v, suffix)
        if shav in latin:
            for lat in latin[shav]:
                if any(suffix.startswith(v) for v in 'aeiou'):
                    lat = re.sub('(.+)e$', r'\1', lat)
                if not any(lat + suffix == word for word in output[1]):
                    output[1].append(f"{lat}{suffix}")

    output[1] = sorted(output[1], key = lambda k: k.endswith('ed'), reverse = past)

    if variant >= len(output[1]) or len(output[1]) == 0:
        raise KeyError('No such variant')
    output[1] = output[1][variant]
    return ''.join([(x or '') for x in output])
