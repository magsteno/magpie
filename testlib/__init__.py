#### magpielib, tools for converting steno into shavian and shavian into latin

# used to get a list of active dictionaries to pull prefixed terms froms
from plover import config
from typing import Tuple
currentconfig = config.Config(r'.\plover.cfg')

# each chord in the strokes dictionary is assigned a specific consonant cluster or vowel. sorted loosely based on standard shavian order
# rhotic clusters lack the letter ð‘® because these already exist in the vowel. rhotic vowels lack the R in the chord because these already exist in the final
strokesDict = {
    'initials': {'': '', 'ð‘¦': 'ð‘¦',
        'ð‘': 'ð‘', 'ð‘ð‘£ð‘®': 'ð‘ð‘¤', 'ð‘ð‘®': 'ð‘ð‘®', 'ð‘ð‘¢': 'ð‘š', 'ð‘ð‘¢ð‘£ð‘®': 'ð‘šð‘¤', 'ð‘ð‘¢ð‘®': 'ð‘šð‘®',
        'ð‘‘': 'ð‘‘', 'ð‘‘ð‘¢': 'ð‘‘ð‘¢', 'ð‘‘ð‘®': 'ð‘‘ð‘®', 'ð‘‘ð‘’': 'ð‘›', 'ð‘‘ð‘’ð‘¢': 'ð‘›ð‘¢', 'ð‘‘ð‘’ð‘®': 'ð‘›ð‘®',
        'ð‘’': 'ð‘’', 'ð‘’ð‘¢': 'ð‘’ð‘¢', 'ð‘’ð‘£ð‘®': 'ð‘’ð‘¤', 'ð‘’ð‘®': 'ð‘’ð‘®', 'ð‘•ð‘‘ð‘’': 'ð‘œ', 'ð‘•ð‘‘ð‘’ð‘¢': 'ð‘œð‘¢', 'ð‘•ð‘‘ð‘’ð‘£ð‘®': 'ð‘œð‘¤', 'ð‘•ð‘‘ð‘’ð‘®': 'ð‘œð‘®',
        'ð‘‘ð‘': 'ð‘“', 'ð‘‘ð‘ð‘£ð‘®': 'ð‘“ð‘¤', 'ð‘‘ð‘ð‘®': 'ð‘“ð‘®', 'ð‘‘ð‘ð‘¢': 'ð‘', 'ð‘‘ð‘ð‘¢ð‘®': 'ð‘ð‘®',
        'ð‘‘ð‘£': 'ð‘”', 'ð‘‘ð‘¢ð‘£': 'ð‘”ð‘¢', 'ð‘‘ð‘£ð‘®': 'ð‘”ð‘®', 'ð‘‘ð‘’ð‘£': 'ð‘ž',
        'ð‘•': 'ð‘•', 'ð‘•ð‘': 'ð‘•ð‘', 'ð‘•ð‘ð‘£ð‘®': 'ð‘•ð‘ð‘¤', 'ð‘•ð‘ð‘®': 'ð‘•ð‘ð‘®', 'ð‘•ð‘‘': 'ð‘•ð‘‘', 'ð‘•ð‘‘ð‘®': 'ð‘•ð‘‘ð‘®', 'ð‘•ð‘’': 'ð‘•ð‘’', 'ð‘•ð‘’ð‘£ð‘®': 'ð‘•ð‘’ð‘¤', 'ð‘•ð‘’ð‘®': 'ð‘•ð‘’ð‘®', 'ð‘•ð‘’ð‘¢': 'ð‘•ð‘’ð‘¢', 'ð‘•ð‘‘ð‘': 'ð‘•ð‘“', 'ð‘•ð‘¢': 'ð‘•ð‘¢', 'ð‘•ð‘£ð‘®': 'ð‘•ð‘¤', 'ð‘•ð‘ð‘£': 'ð‘•ð‘¥', 'ð‘•ð‘‘ð‘ð‘£': 'ð‘•ð‘¯', 'ð‘•ð‘®': 'ð‘Ÿ',
        'ð‘’ð‘': 'ð‘–', 'ð‘’ð‘ð‘£ð‘®': 'ð‘–ð‘¤', 'ð‘’ð‘ð‘®': 'ð‘–ð‘®', 'ð‘’ð‘ð‘¢': 'ð‘ ',
        'ð‘‘ð‘’ð‘': 'ð‘—', 'ð‘‘ð‘’ð‘ð‘¢': 'ð‘¡',
        'ð‘’ð‘¢ð‘®': 'ð‘˜', 'ð‘¢': 'ð‘¢',
        'ð‘•ð‘‘ð‘’ð‘ð‘£': 'ð‘™', 'ð‘•ð‘‘ð‘’ð‘ð‘¢ð‘£': 'ð‘™ð‘¢',
        'ð‘£': 'ð‘£', 'ð‘¢ð‘£': 'ð‘£ð‘¢',
        'ð‘£ð‘®': 'ð‘¤', 'ð‘®': 'ð‘®',
        'ð‘ð‘£': 'ð‘¥', 'ð‘‘ð‘ð‘£': 'ð‘¯'},
    'nonrhotic': {'': '',
        'ð‘': 'ð‘', 'ð‘ð‘‘': 'ð‘ð‘‘', 'ð‘ð‘‘ð‘•': 'ð‘ð‘‘ð‘•', 'ð‘ð‘‘ð‘›': 'ð‘ð‘”', 'ð‘ð‘‘ð‘›ð‘Ÿ': 'ð‘ð‘”ð‘•', 'ð‘ð‘•': 'ð‘ð‘•', 'ð‘ð‘•ð‘›': 'ð‘ð‘•ð‘‘', 'ð‘ð‘šð‘‘': 'ð‘ð‘•ð‘‘',
        'ð‘š': 'ð‘š', 'ð‘šð‘›': 'ð‘šð‘›', 'ð‘šð‘›ð‘Ÿ': 'ð‘šð‘›ð‘Ÿ', 'ð‘šð‘Ÿ': 'ð‘šð‘Ÿ',
        'ð‘‘': 'ð‘‘', 'ð‘¤ð‘‘ð‘›': 'ð‘‘ð‘”', 'ð‘¤ð‘‘ð‘›ð‘Ÿ': 'ð‘‘ð‘”ð‘•', 'ð‘‘ð‘•': 'ð‘‘ð‘•', 'ð‘‘ð‘•ð‘›': 'ð‘‘ð‘•ð‘‘',
        'ð‘›': 'ð‘›', 'ð‘¤ð‘œ': 'ð‘›', 'ð‘¤ð‘œð‘‘ð‘›': 'ð‘›ð‘”', 'ð‘¤ð‘œð‘‘ð‘›ð‘Ÿ': 'ð‘›ð‘”ð‘•', 'ð‘›ð‘Ÿ': 'ð‘›ð‘Ÿ', 'ð‘¤ð‘œð‘Ÿ': 'ð‘›ð‘Ÿ', 'ð‘¤ð‘œð‘•ð‘›': 'ð‘›ð‘Ÿð‘›',
        'ð‘šð‘œ': 'ð‘’', 'ð‘šð‘œð‘‘': 'ð‘’ð‘‘', 'ð‘œð‘‘': 'ð‘’ð‘‘', 'ð‘šð‘œð‘‘ð‘•': 'ð‘’ð‘‘ð‘•', 'ð‘œð‘‘ð‘•': 'ð‘’ð‘‘ð‘•', 'ð‘šð‘œð‘‘ð‘›': 'ð‘’ð‘”', 'ð‘šð‘œð‘‘ð‘›ð‘Ÿ': 'ð‘’ð‘”ð‘•', 'ð‘šð‘œð‘•': 'ð‘’ð‘•', 'ð‘œð‘•': 'ð‘’ð‘•', 'ð‘šð‘œð‘•ð‘›': 'ð‘’ð‘•ð‘‘', 'ð‘œð‘•ð‘›': 'ð‘’ð‘•ð‘‘', 'ð‘šð‘œð‘•ð‘›ð‘Ÿ': 'ð‘’ð‘•ð‘‘ð‘•', 'ð‘œð‘•ð‘›ð‘Ÿ': 'ð‘’ð‘•ð‘‘ð‘•', 'ð‘šð‘œð‘‘ð‘•ð‘›': 'ð‘’ð‘•ð‘”', 'ð‘œð‘‘ð‘•ð‘›': 'ð‘’ð‘•ð‘”', 'ð‘šð‘œð‘‘ð‘•ð‘›ð‘Ÿ': 'ð‘’ð‘•ð‘”ð‘•', 'ð‘œð‘‘ð‘•ð‘›ð‘Ÿ': 'ð‘’ð‘•ð‘”ð‘•',
        'ð‘œ': 'ð‘œ', 'ð‘œð‘›': 'ð‘œð‘›', 'ð‘œð‘›ð‘Ÿ': 'ð‘œð‘›ð‘Ÿ', 'ð‘œð‘‘ð‘›': 'ð‘œð‘”', 'ð‘œð‘‘ð‘›ð‘Ÿ': 'ð‘œð‘”ð‘•', 'ð‘œð‘Ÿ': 'ð‘œð‘Ÿ',
        'ð‘“': 'ð‘“', 'ð‘“ð‘‘': 'ð‘“ð‘‘', 'ð‘“ð‘‘ð‘•': 'ð‘“ð‘‘ð‘•', 'ð‘“ð‘‘ð‘›': 'ð‘“ð‘”', 'ð‘“ð‘‘ð‘›ð‘Ÿ': 'ð‘“ð‘”ð‘•', 'ð‘“ð‘•': 'ð‘“ð‘•', 'ð‘“ð‘•ð‘›': 'ð‘“ð‘•ð‘‘',
        'ð‘ð‘šð‘¤': 'ð‘', 'ð‘ð‘šð‘¤ð‘›': 'ð‘ð‘›', 'ð‘“ð‘›': 'ð‘ð‘›', 'ð‘ð‘šð‘¤ð‘‘ð‘›': 'ð‘ð‘”', 'ð‘ð‘šð‘¤ð‘‘ð‘›ð‘Ÿ': 'ð‘ð‘”ð‘•', 'ð‘ð‘šð‘¤ð‘Ÿ': 'ð‘ð‘Ÿ', 'ð‘“ð‘Ÿ': 'ð‘ð‘Ÿ',
        'ð‘‘ð‘›': 'ð‘”', 'ð‘“ð‘¤ð‘‘': 'ð‘”ð‘‘', 'ð‘“ð‘¤ð‘‘ð‘•': 'ð‘”ð‘‘ð‘•', 'ð‘“ð‘¤ð‘•': 'ð‘”ð‘•', 'ð‘‘ð‘›ð‘Ÿ': 'ð‘”ð‘•', 'ð‘“ð‘¤ð‘•ð‘›': 'ð‘”ð‘•ð‘‘',
        'ð‘“ð‘¤ð‘œ': 'ð‘ž', 'ð‘“ð‘¤ð‘œð‘›': 'ð‘žð‘›', 'ð‘“ð‘¤ð‘œð‘Ÿ': 'ð‘žð‘Ÿ',
        'ð‘•': 'ð‘•', 'ð‘“ð‘': 'ð‘•ð‘', 'ð‘“ð‘ð‘•': 'ð‘•ð‘ð‘•', 'ð‘“ð‘ð‘•ð‘›': 'ð‘•ð‘ð‘•ð‘‘', 'ð‘“ð‘ð‘‘': 'ð‘•ð‘ð‘‘', 'ð‘“ð‘ð‘‘ð‘•': 'ð‘•ð‘ð‘‘ð‘•', 'ð‘•ð‘›': 'ð‘•ð‘‘', 'ð‘šð‘‘': 'ð‘•ð‘‘', 'ð‘•ð‘›ð‘Ÿ': 'ð‘•ð‘‘ð‘•', 'ð‘šð‘‘ð‘•': 'ð‘•ð‘‘ð‘•', 'ð‘“ð‘šð‘œ': 'ð‘•ð‘’', 'ð‘“ð‘šð‘œð‘‘': 'ð‘•ð‘’ð‘‘', 'ð‘“ð‘šð‘œð‘‘ð‘•': 'ð‘•ð‘’ð‘‘ð‘•', 'ð‘“ð‘šð‘œð‘•': 'ð‘•ð‘’ð‘•', 'ð‘“ð‘šð‘œð‘•ð‘›': 'ð‘•ð‘’ð‘•ð‘‘', 'ð‘šð‘‘ð‘›': 'ð‘•ð‘”', 'ð‘šð‘‘ð‘›ð‘Ÿ': 'ð‘•ð‘”ð‘•',
        'ð‘Ÿ': 'ð‘Ÿ', 'ð‘šð‘•': 'ð‘Ÿ', 'ð‘šð‘¤ð‘œ': 'ð‘Ÿð‘›', 'ð‘šð‘‘ð‘•ð‘›': 'ð‘Ÿð‘”', 'ð‘šð‘‘ð‘•ð‘›ð‘Ÿ': 'ð‘Ÿð‘”ð‘•',
        'ð‘ð‘œ': 'ð‘–', 'ð‘ð‘œð‘‘': 'ð‘–ð‘‘', 'ð‘ð‘œð‘‘ð‘•': 'ð‘–ð‘‘ð‘•', 'ð‘ð‘œð‘‘ð‘›': 'ð‘–ð‘”', 'ð‘ð‘œð‘‘ð‘›ð‘Ÿ': 'ð‘–ð‘”ð‘•',
        'ð‘ð‘œð‘Ÿ': 'ð‘ ', 'ð‘ð‘šð‘œð‘›': 'ð‘ ð‘›', 'ð‘ð‘œð‘›': 'ð‘ ð‘›', 'ð‘ð‘šð‘œð‘›ð‘Ÿ': 'ð‘ ð‘›ð‘Ÿ', 'ð‘ð‘œð‘›ð‘Ÿ': 'ð‘ ð‘›ð‘Ÿ',
        'ð‘ð‘¤ð‘œ': 'ð‘—', 'ð‘ð‘¤ð‘œð‘‘': 'ð‘—ð‘‘', 'ð‘ð‘¤ð‘œð‘‘ð‘•': 'ð‘—ð‘‘ð‘•', 'ð‘ð‘¤ð‘œð‘‘ð‘›': 'ð‘—ð‘”', 'ð‘ð‘¤ð‘œð‘‘ð‘›ð‘Ÿ': 'ð‘—ð‘”ð‘•',
        'ð‘ð‘šð‘¤ð‘œ': 'ð‘¡', 'ð‘ð‘¤ð‘œð‘Ÿ': 'ð‘¡', 'ð‘ð‘šð‘¤ð‘œð‘›': 'ð‘¡ð‘›', 'ð‘ð‘¤ð‘œð‘›': 'ð‘¡ð‘›', 'ð‘ð‘šð‘¤ð‘œð‘›ð‘Ÿ': 'ð‘¡ð‘›ð‘Ÿ', 'ð‘ð‘¤ð‘œð‘›ð‘Ÿ': 'ð‘¡ð‘›ð‘Ÿ', 'ð‘ð‘šð‘¤ð‘œð‘‘ð‘›': 'ð‘¡ð‘”', 'ð‘ð‘šð‘¤ð‘œð‘‘ð‘›ð‘Ÿ': 'ð‘¡ð‘”ð‘•',
        'ð‘ð‘š': 'ð‘™', 'ð‘ð‘šð‘›': 'ð‘™ð‘›', 'ð‘ð‘šð‘›ð‘Ÿ': 'ð‘™ð‘›ð‘Ÿ', 'ð‘ð‘šð‘œ': 'ð‘™ð‘’', 'ð‘ð‘šð‘œð‘‘': 'ð‘™ð‘’ð‘‘', 'ð‘ð‘šð‘œð‘‘ð‘•': 'ð‘™ð‘’ð‘‘ð‘•', 'ð‘ð‘šð‘œð‘‘ð‘›': 'ð‘™ð‘’ð‘”', 'ð‘ð‘šð‘œð‘‘ð‘›ð‘Ÿ': 'ð‘™ð‘’ð‘”ð‘•', 'ð‘ð‘šð‘œð‘•': 'ð‘™ð‘’ð‘•', 'ð‘ð‘šð‘œð‘•ð‘›': 'ð‘™ð‘’ð‘•ð‘‘', 'ð‘ð‘šð‘œð‘•ð‘›ð‘Ÿ': 'ð‘™ð‘’ð‘•ð‘‘ð‘•', 'ð‘“ð‘œ': 'ð‘™ð‘œ', 'ð‘“ð‘œð‘›': 'ð‘™ð‘œð‘›', 'ð‘“ð‘œð‘›ð‘Ÿ': 'ð‘™ð‘œð‘›ð‘Ÿ', 'ð‘“ð‘œð‘Ÿ': 'ð‘™ð‘œð‘Ÿ', 'ð‘ð‘šð‘‘ð‘›': 'ð‘™ð‘”', 'ð‘ð‘šð‘‘ð‘›ð‘Ÿ': 'ð‘™ð‘”ð‘•', 'ð‘ð‘šð‘•': 'ð‘™ð‘•', 'ð‘ð‘šð‘•ð‘›': 'ð‘™ð‘•ð‘‘', 'ð‘ð‘šð‘•ð‘›ð‘Ÿ': 'ð‘™ð‘•ð‘‘ð‘•', 'ð‘ð‘šð‘Ÿ': 'ð‘™ð‘Ÿ',
        'ð‘¤': 'ð‘¤', 'ð‘“ð‘®ð‘': 'ð‘¤ð‘', 'ð‘“ð‘®ð‘ð‘‘': 'ð‘¤ð‘ð‘‘', 'ð‘“ð‘®ð‘ð‘‘ð‘•': 'ð‘¤ð‘ð‘‘ð‘•', 'ð‘“ð‘®ð‘ð‘•': 'ð‘¤ð‘ð‘•', 'ð‘“ð‘®ð‘ð‘•ð‘›': 'ð‘¤ð‘ð‘•ð‘‘', 'ð‘“ð‘®ð‘ð‘š': 'ð‘¤ð‘š', 'ð‘“ð‘®ð‘ð‘šð‘›': 'ð‘¤ð‘šð‘›', 'ð‘“ð‘®ð‘ð‘šð‘Ÿ': 'ð‘¤ð‘šð‘Ÿ',
        'ð‘¤ð‘‘': 'ð‘¤ð‘‘', 'ð‘¤ð‘‘ð‘•': 'ð‘¤ð‘‘ð‘•', 'ð‘¤ð‘‘ð‘•ð‘›': 'ð‘¤ð‘‘ð‘•ð‘‘', 'ð‘¤ð‘›': 'ð‘¤ð‘›', 'ð‘“ð‘®ð‘¤ð‘œ': 'ð‘¤ð‘›', 'ð‘¤ð‘›ð‘Ÿ': 'ð‘¤ð‘›ð‘Ÿ', 'ð‘“ð‘®ð‘¤ð‘œð‘Ÿ': 'ð‘¤ð‘›ð‘Ÿ',
        'ð‘“ð‘®ð‘šð‘œ': 'ð‘¤ð‘’', 'ð‘“ð‘®ð‘šð‘œð‘‘': 'ð‘¤ð‘’ð‘‘', 'ð‘“ð‘®ð‘šð‘œð‘‘ð‘•': 'ð‘¤ð‘’ð‘‘ð‘•', 'ð‘“ð‘®ð‘šð‘œð‘•': 'ð‘¤ð‘’ð‘•', 'ð‘“ð‘®ð‘šð‘œð‘•ð‘›': 'ð‘¤ð‘’ð‘•ð‘‘', 'ð‘“ð‘®ð‘œ': 'ð‘¤ð‘œ', 'ð‘“ð‘®ð‘œð‘›': 'ð‘¤ð‘œð‘›', 'ð‘“ð‘®ð‘œð‘Ÿ': 'ð‘¤ð‘œð‘Ÿ',
        'ð‘“ð‘®ð‘ð‘¤': 'ð‘¤ð‘“', 'ð‘“ð‘®ð‘ð‘¤ð‘‘': 'ð‘¤ð‘“ð‘‘', 'ð‘“ð‘®ð‘ð‘¤ð‘‘ð‘•': 'ð‘¤ð‘“ð‘‘ð‘•', 'ð‘“ð‘®ð‘ð‘¤ð‘‘ð‘›': 'ð‘¤ð‘“ð‘”', 'ð‘“ð‘®ð‘ð‘¤ð‘‘ð‘›ð‘Ÿ': 'ð‘¤ð‘“ð‘”ð‘•', 'ð‘“ð‘®ð‘ð‘¤ð‘•': 'ð‘¤ð‘“ð‘•', 'ð‘“ð‘®ð‘ð‘¤ð‘•ð‘›': 'ð‘¤ð‘“ð‘•ð‘‘', 'ð‘“ð‘®ð‘ð‘šð‘¤': 'ð‘¤ð‘', 'ð‘“ð‘®ð‘ð‘šð‘¤ð‘›': 'ð‘¤ð‘ð‘›', 'ð‘“ð‘®ð‘ð‘šð‘¤ð‘Ÿ': 'ð‘¤ð‘ð‘Ÿ',
        'ð‘“ð‘®ð‘¤': 'ð‘¤ð‘”', 'ð‘“ð‘®ð‘¤ð‘‘': 'ð‘¤ð‘”ð‘‘', 'ð‘“ð‘®ð‘¤ð‘‘ð‘•': 'ð‘¤ð‘”ð‘‘ð‘•', 'ð‘“ð‘®ð‘¤ð‘•': 'ð‘¤ð‘”ð‘•', 'ð‘“ð‘®ð‘¤ð‘•ð‘›': 'ð‘¤ð‘”ð‘•ð‘‘',
        'ð‘¤ð‘•': 'ð‘¤ð‘•', 'ð‘¤ð‘•ð‘›': 'ð‘¤ð‘•ð‘‘', 'ð‘¤ð‘Ÿ': 'ð‘¤ð‘Ÿ', 'ð‘“ð‘®ð‘šð‘•': 'ð‘¤ð‘Ÿ', 'ð‘“ð‘®ð‘šð‘¤ð‘œ': 'ð‘¤ð‘Ÿð‘›', 'ð‘“ð‘®ð‘šð‘•ð‘›': 'ð‘¤ð‘Ÿð‘›',
        'ð‘“ð‘®ð‘ð‘œ': 'ð‘¤ð‘–', 'ð‘“ð‘®ð‘ð‘œð‘‘': 'ð‘¤ð‘–ð‘‘', 'ð‘“ð‘®ð‘ð‘šð‘œ': 'ð‘¤ð‘ ', 'ð‘“ð‘®ð‘ð‘šð‘œð‘›': 'ð‘¤ð‘ ð‘›',
        'ð‘“ð‘®ð‘ð‘¤ð‘œ': 'ð‘¤ð‘—', 'ð‘“ð‘®ð‘ð‘¤ð‘œð‘‘': 'ð‘¤ð‘—ð‘‘', 'ð‘“ð‘®ð‘ð‘šð‘¤ð‘œ': 'ð‘¤ð‘¡', 'ð‘“ð‘®ð‘ð‘šð‘¤ð‘œð‘›': 'ð‘¤ð‘¡ð‘›',
        'ð‘“ð‘šð‘¤': 'ð‘¤ð‘¥', 'ð‘“ð‘šð‘¤ð‘›': 'ð‘¤ð‘¥ð‘›', 'ð‘“ð‘šð‘¤ð‘Ÿ': 'ð‘¤ð‘¥ð‘Ÿ', 'ð‘“ð‘¤': 'ð‘¤ð‘¯', 'ð‘“ð‘¤ð‘›': 'ð‘¤ð‘¯ð‘›', 'ð‘“ð‘¤ð‘Ÿ': 'ð‘¤ð‘¯ð‘Ÿ',
        'ð‘“ð‘š': 'ð‘¥', 'ð‘“ð‘ð‘š': 'ð‘¥ð‘', 'ð‘“ð‘ð‘šð‘‘': 'ð‘¥ð‘ð‘‘', 'ð‘“ð‘ð‘šð‘‘ð‘•': 'ð‘¥ð‘ð‘‘ð‘•', 'ð‘“ð‘ð‘šð‘•': 'ð‘¥ð‘ð‘•', 'ð‘“ð‘ð‘šð‘•ð‘›': 'ð‘¥ð‘ð‘•ð‘‘', 'ð‘“ð‘ð‘šð‘¤': 'ð‘¥ð‘“', 'ð‘“ð‘ð‘šð‘¤ð‘•': 'ð‘¥ð‘“ð‘•', 'ð‘“ð‘ð‘šð‘¤ð‘•ð‘›': 'ð‘¥ð‘“ð‘•ð‘‘', 'ð‘“ð‘ð‘šð‘¤ð‘‘': 'ð‘¥ð‘“ð‘‘', 'ð‘“ð‘ð‘šð‘¤ð‘‘ð‘•': 'ð‘¥ð‘“ð‘‘ð‘•', 'ð‘“ð‘šð‘‘': 'ð‘¥ð‘‘', 'ð‘“ð‘šð‘‘ð‘•': 'ð‘¥ð‘‘ð‘•', 'ð‘“ð‘šð‘›': 'ð‘¥ð‘›', 'ð‘“ð‘šð‘›ð‘Ÿ': 'ð‘¥ð‘›ð‘Ÿ', 'ð‘“ð‘šð‘‘ð‘›': 'ð‘¥ð‘”', 'ð‘“ð‘šð‘‘ð‘›ð‘Ÿ': 'ð‘¥ð‘”ð‘•', 'ð‘“ð‘šð‘Ÿ': 'ð‘¥ð‘Ÿ',
        'ð‘“ð‘ð‘¤': 'ð‘¯', 'ð‘“ð‘ð‘¤ð‘‘': 'ð‘¯ð‘‘', 'ð‘“ð‘ð‘¤ð‘‘ð‘•': 'ð‘¯ð‘‘ð‘•', 'ð‘“ð‘ð‘¤ð‘›': 'ð‘¯ð‘›', 'ð‘“ð‘ð‘¤ð‘›ð‘Ÿ': 'ð‘¯ð‘›ð‘Ÿ', 'ð‘“ð‘ð‘¤ð‘‘ð‘›': 'ð‘¯ð‘”', 'ð‘“ð‘ð‘¤ð‘‘ð‘›ð‘Ÿ': 'ð‘¯ð‘”ð‘•', 'ð‘“ð‘ð‘¤ð‘•': 'ð‘¯ð‘•', 'ð‘šð‘•ð‘›': 'ð‘¯ð‘•ð‘‘', 'ð‘“ð‘ð‘¤ð‘Ÿ': 'ð‘¯ð‘Ÿ', 'ð‘“ð‘ð‘œ': 'ð‘¯ð‘–', 'ð‘“ð‘ð‘œð‘‘': 'ð‘¯ð‘–ð‘‘', 'ð‘“ð‘ð‘šð‘œ': 'ð‘¯ð‘ ', 'ð‘“ð‘ð‘šð‘œð‘›': 'ð‘¯ð‘ ð‘›', 'ð‘“ð‘ð‘œð‘›': 'ð‘¯ð‘ ð‘›', 'ð‘“ð‘ð‘¤ð‘œ': 'ð‘¯ð‘—', 'ð‘“ð‘ð‘¤ð‘œð‘‘': 'ð‘¯ð‘—ð‘‘', 'ð‘“ð‘ð‘šð‘¤ð‘œ': 'ð‘¯ð‘¡', 'ð‘“ð‘ð‘šð‘¤ð‘œð‘›': 'ð‘¯ð‘¡ð‘›',
        'ð‘§ð‘³': 'ð‘¦', 'ð‘¨ð‘ªð‘§ð‘³': 'ð‘°', 'ð‘§': 'ð‘§', 'ð‘¨ð‘ªð‘§': 'ð‘±', 'ð‘¨': 'ð‘¨', 'ð‘¨ð‘ªð‘³': 'ð‘²', '*': 'ð‘©', '*ð‘³': 'ð‘©', 'ð‘³': 'ð‘³', 'ð‘ª': 'ð‘ª', 'ð‘ªð‘³': 'ð‘´', 'ð‘¨ð‘ª': 'ð‘«', 'ð‘¨ð‘§': 'ð‘µ', 'ð‘¨ð‘³': 'ð‘¬', 'ð‘ªð‘§': 'ð‘¶', 'ð‘¨ð‘§ð‘³': 'ð‘­', 'ð‘ªð‘§ð‘³': 'ð‘·', '*ð‘§': 'ð‘§ð‘©', 'ð‘¨ð‘ª*ð‘§ð‘³': 'ð‘¾', '*ð‘§ð‘³': 'ð‘¾', 'ð‘¨*ð‘§': 'ð‘¿', 'ð‘¨ð‘ª*': 'ð‘˜ð‘©'},
    'rhotic': {'ð‘®': '',
        'ð‘®ð‘': 'ð‘', 'ð‘®ð‘ð‘‘': 'ð‘ð‘‘', 'ð‘®ð‘ð‘‘ð‘•': 'ð‘ð‘‘ð‘•', 'ð‘®ð‘ð‘•': 'ð‘ð‘•', 'ð‘®ð‘ð‘•ð‘›': 'ð‘ð‘•ð‘‘', 'ð‘®ð‘š': 'ð‘š', 'ð‘®ð‘šð‘›': 'ð‘šð‘›', 'ð‘®ð‘šð‘Ÿ': 'ð‘šð‘Ÿ',
        'ð‘®ð‘‘': 'ð‘‘', 'ð‘®ð‘‘ð‘•': 'ð‘‘ð‘•', 'ð‘®ð‘‘ð‘•ð‘›': 'ð‘‘ð‘•ð‘‘', 'ð‘®ð‘›': 'ð‘›', 'ð‘®ð‘¤ð‘œ': 'ð‘›', 'ð‘®ð‘›ð‘Ÿ': 'ð‘›ð‘Ÿ', 'ð‘®ð‘¤ð‘œð‘Ÿ': 'ð‘›ð‘Ÿ',
        'ð‘®ð‘šð‘œ': 'ð‘’', 'ð‘®ð‘šð‘œð‘‘': 'ð‘’ð‘‘', 'ð‘®ð‘šð‘œð‘‘ð‘•': 'ð‘’ð‘‘ð‘•', 'ð‘®ð‘šð‘œð‘•': 'ð‘’ð‘•', 'ð‘®ð‘šð‘œð‘•ð‘›': 'ð‘’ð‘•ð‘‘', 'ð‘®ð‘œ': 'ð‘œ', 'ð‘®ð‘œð‘›': 'ð‘œð‘›', 'ð‘®ð‘œð‘Ÿ': 'ð‘œð‘Ÿ',
        'ð‘“ð‘®': 'ð‘“', 'ð‘“ð‘®ð‘‘': 'ð‘“ð‘‘', 'ð‘“ð‘®ð‘‘ð‘•': 'ð‘“ð‘‘ð‘•', 'ð‘“ð‘®ð‘•': 'ð‘“ð‘•', 'ð‘“ð‘®ð‘•ð‘›': 'ð‘“ð‘•ð‘‘', 'ð‘®ð‘ð‘šð‘¤': 'ð‘', 'ð‘®ð‘ð‘šð‘¤ð‘›': 'ð‘ð‘›', 'ð‘“ð‘®ð‘›': 'ð‘ð‘›', 'ð‘®ð‘ð‘šð‘¤ð‘Ÿ': 'ð‘ð‘Ÿ', 'ð‘“ð‘®ð‘Ÿ': 'ð‘ð‘Ÿ',
        'ð‘®ð‘‘ð‘›': 'ð‘”', 'ð‘“ð‘®ð‘¤ð‘œð‘‘': 'ð‘”ð‘‘', 'ð‘®ð‘‘ð‘›ð‘Ÿ': 'ð‘”ð‘•', 'ð‘“ð‘®ð‘¤ð‘œð‘•': 'ð‘”ð‘•', 'ð‘“ð‘®ð‘¤ð‘œ': 'ð‘ž', 'ð‘“ð‘®ð‘¤ð‘œð‘›': 'ð‘žð‘›', 'ð‘“ð‘®ð‘¤ð‘œð‘Ÿ': 'ð‘žð‘Ÿ',
        'ð‘®ð‘•': 'ð‘•', 'ð‘®ð‘•ð‘›': 'ð‘•ð‘‘', 'ð‘®ð‘šð‘‘': 'ð‘•ð‘‘', 'ð‘®ð‘•ð‘›ð‘Ÿ': 'ð‘•ð‘‘ð‘•', 'ð‘®ð‘šð‘‘ð‘•': 'ð‘•ð‘‘ð‘•', 'ð‘®ð‘Ÿ': 'ð‘Ÿ', 'ð‘®ð‘šð‘•': 'ð‘Ÿ', 'ð‘®ð‘šð‘¤ð‘œ': 'ð‘Ÿð‘›', 'ð‘®ð‘šð‘•ð‘›': 'ð‘Ÿð‘›',
        'ð‘®ð‘ð‘œ': 'ð‘–', 'ð‘®ð‘šð‘œð‘‘': 'ð‘–ð‘‘', 'ð‘®ð‘ð‘šð‘œ': 'ð‘ ', 'ð‘®ð‘ð‘šð‘œð‘›': 'ð‘ ð‘›', 'ð‘®ð‘ð‘œð‘›': 'ð‘ ð‘›',
        'ð‘®ð‘ð‘¤ð‘œ': 'ð‘—', 'ð‘®ð‘ð‘¤ð‘œð‘‘': 'ð‘—ð‘‘', 'ð‘®ð‘ð‘šð‘¤ð‘œ': 'ð‘¡', 'ð‘®ð‘ð‘šð‘¤ð‘œð‘›': 'ð‘¡ð‘›',
        'ð‘®ð‘¤': 'ð‘¤', 'ð‘®ð‘¤ð‘›': 'ð‘¤ð‘›', 'ð‘®ð‘¤ð‘›ð‘Ÿ': 'ð‘¤ð‘›ð‘Ÿ', 'ð‘®ð‘¤ð‘Ÿ': 'ð‘¤ð‘Ÿ',
        'ð‘“ð‘®ð‘š': 'ð‘¥', 'ð‘“ð‘®ð‘šð‘›': 'ð‘¥ð‘›', 'ð‘“ð‘®ð‘šð‘Ÿ': 'ð‘¥ð‘Ÿ', 'ð‘®ð‘ð‘š': 'ð‘¯', 'ð‘®ð‘ð‘šð‘‘': 'ð‘¯ð‘‘', 'ð‘®ð‘ð‘šð‘‘ð‘•': 'ð‘¯ð‘‘ð‘•', 'ð‘®ð‘ð‘šð‘›': 'ð‘¯ð‘›', 'ð‘®ð‘ð‘šð‘•': 'ð‘¯ð‘•', 'ð‘®ð‘ð‘šð‘Ÿ': 'ð‘¯ð‘Ÿ',
        'ð‘¨': 'ð‘¸', 'ð‘ª': 'ð‘¹', 'ð‘§': 'ð‘º', 'ð‘³': 'ð‘»', '*': 'ð‘¼', '*ð‘³': 'ð‘¼', 'ð‘¨ð‘ªð‘§ð‘³': 'ð‘½', 'ð‘§ð‘³': 'ð‘½', 'ð‘¨ð‘ª': 'ð‘«ð‘¼', 'ð‘¨ð‘ª*': 'ð‘˜ð‘«ð‘¼', '*ð‘§ð‘³': 'ð‘˜ð‘¼'}
}

# === dictionary functions ===
def comparejsons():
    import plover

    # reload and compare current plover config to 'briefsDict'
    currentconfig.load()
    enabledjsons = [path for (path, enabled) in currentconfig.__getitem__('dictionaries') if path.endswith('json') and enabled]
    if enabledjsons != currentjsons:
        reloadjsons(enabledjsons)

def reloadjsons(current = [path for (path, enabled) in currentconfig.__getitem__('dictionaries') if path.endswith('json') and enabled]):
    import json, plover
    global currentjsons, briefsDict

    currentjsons = current
    # dictionary for holding briefs
    briefsDict = {}
    # import briefsDict entries from files listed in currentjsons
    for file in currentjsons[::-1]:
        with open(file, encoding='UTF8') as briefsfile:
            filedata = briefsfile.read()
            briefsPacked = json.loads(filedata)

            # extract from the file only keys beginning with a @, add them to briefsDict
            briefsPacked = list(filter(lambda k: k[0][:1] == '@', briefsPacked.items()))
            briefsDict = {**briefsDict, **{k[1:]: v.split(',,,') for k, v in briefsPacked}}
            del filedata, briefsPacked

def reloaddicts():
    import plover, os
    global latin, standardise

    # refresh list of jsons
    currentconfig.load()

    # dictionary to hold the necessary parts of the readlex (Shavian to orthodox dicitonary) in memory
    latin = {}
    # dictionary for correcting 'steno spellings' to readlex standard
    standardise = {}
    with open('.\\shavian\\tsv.cfg') as tsvcfg:
        list = tsvcfg.readlines()
        for tsvdir in list:
            if not os.path.isabs(tsvdir):
                tsvdir = '.\\shavian\\' + tsvdir
            with open(tsvdir, encoding='UTF8') as file:
                for line in file.readlines():
                    line = line.replace('\n','')
                    #split lines and take word and frequency data
                    split = line.split("\t")
                    orth = split[0]
                    #entries in readlex marked with * are corrections of steno spelling
                    if orth[:1] == '*':
                        sten = split[1]
                        standardise[sten] = [orth[1:], sten]
                    else:
                        shav = split[1]
                        freq = int(split[2])
                        if shav not in latin:
                            latin[shav] = {orth: freq}
                        else:
                            latin[shav][orth] = freq
                for entry in latin:
                    latin[entry] = [shav for shav, freq in sorted(latin[entry].items(), key=lambda freq: freq[1], reverse=True)]
    reloadjsons()

# initial load of dictionaries
reloaddicts()


# === utilities ===
### returns $first, changing a final ð‘© to an ð‘« if $last starts with a vowel
def schwu(first,last):
    import re
    if first[-1:] == 'ð‘©' and re.match('[ð‘¦-ð‘­,ð‘°-ð‘¾]', last[:1]) is not None:
        return first[:-1] + 'ð‘«'
    else: return first

### searches for $stroke in strokesDict, returning None if not found
# latinOut = True will return latin spelling if available
def briefsDict_search(stroke, latinOut = False, standard = False):
    comparejsons()
    if stroke in briefsDict:
        output = briefsDict[stroke][-latinOut]
    else:
        output = None
    return output

### separates $shav into words and the joiners that surround them and returns them in a list
# '{^}cat{^} -> ['{^', '', '}', 'cat', '{^}']
# '{^cat}' -> ['{^', 'cat', '}', '', None]
# 'cat{^}' -> [None, None, None, 'cat', '{^}']
def parse_joiners(shav, groups = ('0', '1', '2', '3', '4')):
    import re

    # shav, if tuple or list, will be converted into a string, with None values ignored
    # the primary purpose of this is so the output can be fed back in
    if type(shav) != str:
        shav = ''.join([(i or '') for i in shav])
    dissect = re.match(r'^(?:({\^)([^\{\}]*)(}))?(?:{\^})*(.*?)(?:{\^})*(?<=({\^}))?$', shav).groups()
    sections = []
    # alternative groupings can be specified with $groups
    # parse_joiners('cat', ('012', '34')) == [None, 'cat']
    for combination in groups:
        sections.append(None)
        for part in combination:
            part = dissect[int(part)]
            if part is not None:
                sections[-1] = (sections[-1] or '') + part
    return sections


# === conversion functions for steno dictionaries ===
### 'ð‘•ð‘‘ð‘’ð‘£ð‘®ð‘¨ð‘ªð‘§ð‘šð‘Ÿ' to 'ð‘œð‘¤ð‘±ð‘Ÿ'
def stroke_to_shav(stroke: str) -> str:
    import re

    # === segmenting strokes for searching and parsing ===
    # to make ð‘’ð‘¢ð‘® pass the regex
    if stroke == 'ð‘’ð‘¢ð‘®': stroke += '-'

    # the hash symbol is used to mark where two words join
    if stroke == '#': return '{^}'

    # split 'stroke' into syllable segments (initial, vowels, final) and if prefixed with #, mark for joining to next syllable
    dissect = re.fullmatch(r'(#?)([ð‘•ð‘‘ð‘’ð‘ð‘¢ð‘£ð‘®]*)([ð‘¨ð‘ª*ð‘§ð‘³-]+)([ð‘“ð‘®ð‘ð‘šð‘¤ð‘œð‘‘ð‘•ð‘›ð‘Ÿ]*)', stroke)
    if dissect is None:
        raise KeyError(f'{stroke} is an nvalid stroke')
    (joinsNext, initial, vowel, final) = dissect.groups()


    # === preparation for conversion ===
    # A* = schwa attached to front of syllable
    if vowel.replace('ð‘³','') == 'ð‘¨*':
        joinsNext = True
        vowel = vowel.replace('ð‘¨','')

    # -TZ - alternative joiner (like #)
    if final.replace('ð‘®','') == 'ð‘‘ð‘Ÿ':
        joinsNext = True
        final = final.replace('ð‘‘ð‘Ÿ','')

    # determines rhoticity
    if final in list(strokesDict['rhotic'].keys()):
        rhoticity = 'rhotic'
    else:
        rhoticity = 'nonrhotic'

    # converts Y- into schwi
    if initial == 'ð‘’ð‘¢ð‘®' and (vowel == '-' or (rhoticity == 'nonrhotic' and vowel + strokesDict[rhoticity][final] == '*ð‘•ð‘‘')):
        initial = 'ð‘¦'
        if final == 'ð‘®':
            vowel = '*'
        elif rhoticity == 'rhotic':
            raise KeyError(f'{stroke} is an invalid stroke')
        elif vowel == '-':
            vowel = ''


    # === conversion from steno to raw shavian (illegal strokes will raise KeyError) ===
    shav = strokesDict['initials'][initial] + strokesDict[rhoticity][vowel] + strokesDict[rhoticity][final]


    # === determination of word boundaries ===
    #if vowel is schwa or schwi, or ð‘¾/ð‘½ as a suffix, then {^} at start of syllable
    if (
        any(s in shav for s in 'ð‘©ð‘¼ð‘¾ð‘½')
        and not (
            any(v in shav for v in 'ð‘§ð‘«')
            or (len(vowel) > 3)
            or (vowel == '*' and joinsNext)
        )
    ) or initial == 'ð‘¦':
        if vowel == '*' and final == '':
            raise KeyError('* cannot end a word (try *U)')
        shav = '{^}' + shav

    if joinsNext:
        shav += '{^}'

    return(shav)


### ('#ð‘‘ð‘*', 'ð‘‘ð‘ð‘£ð‘§ð‘‘', 'ð‘’ð‘¢ð‘®-ð‘šð‘œð‘•') into 'ð‘“ð‘©ð‘¯ð‘§ð‘‘ð‘¦ð‘’ð‘•'
def steno_to_shav(steno: Tuple[str], standard = False) -> str:
    output = None

    # special exception for the ð‘³ -> ð‘© brief
    if steno[-1] == 'ð‘³':
        raise KeyError('article, not part of stroke')

    # == separate variant markers from strokes ==
    for varindex in range(len(steno)):
        if steno[varindex] == '-ð‘®ð‘š' and all(chain == '-ð‘®ð‘š' for chain in steno[varindex:]):
            variant = len(steno) - varindex
            break
    else:
        variant = 0

    for stroke in steno[:-variant or None]:
        if output == '{^}{^}':
            raise KeyError(f'outline {steno} starts with no phonetic information')

        syllable = briefsDict_search(stroke)
        previous = parse_joiners(output or '{^}', ('0123','4'))

        # == convert stroke to dissected tuple ==
        # 'ð‘’ð‘¢ð‘®-ð‘šð‘œð‘•' to ('{^}', 'ð‘¦ð‘’ð‘•', None)
        if syllable is not None: # if stroke is in strokesDict, split
            syllable = parse_joiners(syllable)
        # if stroke was not in strokesDict, or no joiners in output
        if syllable is None or syllable[0] == syllable[4]:
            stroke = stroke_to_shav(stroke)
            syllable = parse_joiners(stroke, ('012', '3', '4'))
        # else, if joiners in output (stroke is a prefix stroke)
        else:
            syllable = parse_joiners(syllable, ('02', '1', '34'))

        # == update previous and commit to output if strokes connect ==
        previous[0] = schwu(previous[0], syllable[1] or '')
        # if joiner at end of $previous or start of $syllable
        if previous[1] or syllable[0]:
            # adds syllable to output without intermediary joiners; None -> ''
            output = ''.join([(x or '') for x in previous[:bool(output)] + syllable[bool(output):]])
        else:
            raise KeyError('Word boundary within outline')

    if standard:
        output = parse_joiners(output, ('012', '3', '4'))
        if output[1] in standardise:
            output = standardise[output[1]][bool(variant)]
            if variant:
                variant -= 1
        output = ''.join([(x or '') for x in output])

    return output, variant

def shav_to_latin(shav: str, variant: int = 0) -> str:
    output = parse_joiners(shav, ('012', '3', '4'))
    output[1] = latin[output[1]]
    if variant >= len(output[1]):
        raise KeyError('No such variant')
    output[1] = output[1][variant]
    return ''.join([(x or '') for x in output])
